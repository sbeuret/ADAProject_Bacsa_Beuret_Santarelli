{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Data from the Web \n",
    " By Kiran Bacsa, Samuel Beuret, and Valentine Santarelli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json \n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_palette('Blues')\n",
    "sns.set_context(\"notebook\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  200 top-ranking universities in www.topuniversities.com ([ranking 2018](https://www.topuniversities.com/university-rankings/world-university-rankings/2018)). \n",
    "\n",
    "### Scrapping the web page \n",
    "Using Postman, part of the information needed was found  in a JSON file (name, rank, country, and region). The remaining information to scrap using Beautiful Soup was found on each university's page in the *div* of *class = faculty-main* . \n",
    "* number of faculty members international corresponds to the *div* of *class=inter faculty*\n",
    "* number of faculty members total corresponds to the *div* of *class=total faculty*\n",
    "* number of students international corresponds to the *div* of *class=total inter*\n",
    "* number of students total corresponds to the *div* of *class=total student*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# get name, rank, country and region of the 200 first universities\n",
    "\n",
    "#url found using Postman\n",
    "url='https://www.topuniversities.com/sites/default/files/qs-rankings-data/357051.txt?_=1508005996450'\n",
    "universities= requests.get(url).json()['data'][0:200] #take the first 200 universities\n",
    "#first part of the dataframe for topuniversities.com\n",
    "df_qs1 = pd.DataFrame(universities)\n",
    "df_qs1 = df_qs1.drop(['cc','core_id','guide', 'logo','score','stars','nid'], axis=1) #don't need this information\n",
    "\n",
    "#list of urls to universities pages\n",
    "urls =list(df_qs1['url'])\n",
    "\n",
    "# function to get the rest of the needed information on each university page in a dictionnary\n",
    "def get_details(url):\n",
    "    university= requests.get('https://www.topuniversities.com' + url)\n",
    "    soup= BeautifulSoup(university.text,'html.parser')\n",
    "    data= soup.find_all('div', class_= 'faculty-main') \n",
    "\n",
    "    # number of faculty members international\n",
    "    if(soup.find_all('div', class_ = 'inter faculty') != []):\n",
    "        inter_fac_mem = float(soup.find_all('div', class_ = 'inter faculty')[0].find_all('div', class_ = 'number')[0].string.replace(',',''))\n",
    "    else:\n",
    "        inter_fac_mem = float('nan')\n",
    "        \n",
    "    # number of faculty members total\n",
    "    if(soup.find_all('div', class_ = 'total faculty')!= []):\n",
    "        total_fac_mem = float(soup.find_all('div', class_ = 'total faculty')[0].find_all('div', class_ = 'number')[0].string.replace(',',''))\n",
    "    else:\n",
    "        total_fac_mem = float('nan')\n",
    "        \n",
    "    # number of students international\n",
    "    if(soup.find_all('div', class_ = 'total inter')!= []):\n",
    "        inter_student = float(soup.find_all('div', class_ = 'total inter')[0].find_all('div', class_ = 'number')[0].string.replace(',',''))\n",
    "    else:\n",
    "        inter_student = float('nan')\n",
    "        \n",
    "    # number of students total\n",
    "    if(soup.find_all('div', class_ = 'total student')!= []):\n",
    "        total_student = float(soup.find_all('div', class_ = 'total student')[0].find_all('div', class_ = 'number')[0].string.replace(',',''))\n",
    "    else:\n",
    "        total_student = float('nan')\n",
    "\n",
    "    #output dictionnary (keep the url to merge later)\n",
    "    details = {'url' : url, '(QS) #faculty members international' : inter_fac_mem,\n",
    "          '(QS) #faculty members total' : total_fac_mem,\n",
    "          '(QS) #students international': inter_student,\n",
    "          '(QS) #students total' : total_student}\n",
    "    return details\n",
    "\n",
    "#list of dictionnaries \n",
    "details = []    \n",
    "for url in urls:\n",
    "    details.append(get_details(url))\n",
    "#convert to pd.DataFrame\n",
    "df_qs2 = pd.DataFrame(details)\n",
    "\n",
    "#merge the two dataframes using the url\n",
    "df_qs= pd.merge(df_qs1, df_qs2, 'outer')\n",
    "df_qs.rename(columns={'rank_display': '(QS) rank', 'title': 'name'}, inplace=True)\n",
    "df_qs = df_qs.drop('url', axis=1) #drop the url once the merge is done\n",
    "\n",
    "df_qs.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoid scrapping the web pages every time we need the dataset *df_qs*, the later was exported in a file using the pandas fucntion *to_pickle()*, and imported with *from_pickle()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#USE PICKLE TO SAVE DF\n",
    "filename=\"./data/QS_ranking\"\n",
    "df_qs.to_pickle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE PICKLE TO LOAD DF\n",
    "filename=\"./data/QS_ranking\"\n",
    "df_qs =pd.read_pickle(filename)\n",
    "df_qs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We verify that there is no ties in the ranking and if so, we keep the order of display on the web page.\n",
    "We found the ties using the *duplicated()* pandas function. Each time a duplicate is found (i.e a tie) we increment all the ranks below by one.\n",
    "As expected the rank column is unique at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_qs['(QS) rank']=df_qs['(QS) rank'].str.extract('(\\d+)').astype('int64')\n",
    "bool_dup = df_qs['(QS) rank'].duplicated()\n",
    "ind_dup = bool_dup[bool_dup == True].index\n",
    "\n",
    "#until no more duplicates\n",
    "for ind in ind_dup :\n",
    "    #add +1 the all the ranks below this duplicate\n",
    "    df_qs['(QS) rank'][ind : len(df_qs['(QS) rank'])] = df_qs['(QS) rank'][ind : len(df_qs['(QS) rank']) ] + 1;\n",
    "\n",
    "#verify the rank column is unique i.e no ties   \n",
    "print(df_qs['(QS) rank'].is_unique)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which are the best universities in term of: (a) ratio between faculty members and students, (b) ratio of international students?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adding the ratios to the df_qs dataframe\n",
    "df_qs['(QS) faculty members/students'] = df_qs['(QS) #faculty members total']/df_qs['(QS) #students total']\n",
    "df_qs['(QS) international students/ total students'] = df_qs['(QS) #students international']/df_qs['(QS) #students total']\n",
    "df_qs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plotting the ratio faculty members/students for the 10 first universities\n",
    "df_ratio1 = df_qs.sort_values('(QS) faculty members/students', ascending =False) #sort by ratio\n",
    "df_ratio1.set_index(['name'],inplace=True) #set name of universities as index for the plot\n",
    "df_ratio1= df_ratio1['(QS) faculty members/students'] #extract only the column  needed\n",
    "\n",
    "ax = df_ratio1[0:10].plot.bar()\n",
    "ax.set_xlabel(\"Universities\", fontsize=12)\n",
    "plt.title(\"Ratio between faculty members and students\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best universities in term of ratio of faculty members and students are :\n",
    "* Caltech\n",
    "* Yale University\n",
    "* University of Oxford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plotting the ratio of international students for the first 10 universities\n",
    "df_ratio2 = df_qs.sort_values('(QS) international students/ total students', ascending =False)#sort by ratio\n",
    "df_ratio2.set_index(['name'],inplace=True) #set name of universities as index for the plot\n",
    "df_ratio2= df_ratio2['(QS) international students/ total students']#extract only the column  needed\n",
    "\n",
    "ax = df_ratio2[0:10].plot.bar()\n",
    "ax.set_xlabel(\"Universities\", fontsize=12)\n",
    "plt.title(\"Ratio of international students\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best universities in term of ratio of international students are :\n",
    "* LSE\n",
    "* EPFL\n",
    "* Imperial College London\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which are the best country in term of: (a) ratio between faculty members and students, (b) ratio of international students?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a new dataframe by aggregating values by country.\n",
    "df_country = df_qs.groupby('country').mean()\n",
    "df_country.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sort by ratio and extract the columns needed\n",
    "df_country_ratio1 = df_country.sort_values('(QS) faculty members/students', ascending =False)\n",
    "df_country_ratio1= df_country_ratio1['(QS) faculty members/students']\n",
    "\n",
    "#Plot the sorted countries\n",
    "ax = df_country_ratio1[0:10].plot.bar()\n",
    "ax.set_xlabel(\"Country\", fontsize=12)\n",
    "plt.title(\"Ratio between faculty members and students\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best countries in term of ratio of faculty members and students are :\n",
    "* Russia\n",
    "* Denmark\n",
    "* Saudi Arabia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sort by ratio and extract the columns needed\n",
    "df_country_ratio2 = df_country.sort_values('(QS) international students/ total students', ascending =False)\n",
    "df_country_ratio2= df_country_ratio2['(QS) international students/ total students']\n",
    "\n",
    "#Plot the sorted countries\n",
    "ax = df_country_ratio2[0:10].plot.bar()\n",
    "ax.set_xlabel(\"Country\", fontsize=12)\n",
    "plt.title(\"Ratio of international students\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best countries in term of ratio of international students are :\n",
    "* UK\n",
    "* Australia\n",
    "* Switzerland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which are the best region in term of: (a) ratio between faculty members and students, (b) ratio of international students?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a new dataframe by aggregating values by region.\n",
    "df_region = df_qs.groupby('region').mean()\n",
    "df_region.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sort by ratio and extract the columns needed\n",
    "df_region_ratio1 = df_region.sort_values('(QS) faculty members/students', ascending =False)\n",
    "df_region_ratio1= df_region_ratio1['(QS) faculty members/students']\n",
    "\n",
    "#Plot the sorted regions\n",
    "ax = df_region_ratio1.plot.bar()\n",
    "ax.set_xlabel(\"Region\", fontsize=12)\n",
    "plt.title(\"Ratio between faculty members and students\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best regions in term of ratio of faculty members and students are :\n",
    "* North America\n",
    "* Asia\n",
    "* Europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_region_ratio2 = df_region.sort_values('(QS) international students/ total students', ascending =False)\n",
    "df_region_ratio2= df_region_ratio2['(QS) international students/ total students']\n",
    "\n",
    "ax = df_region_ratio2.plot.bar()\n",
    "ax.set_xlabel(\"Region\", fontsize=12)\n",
    "plt.title(\"Ratio of international students\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best regions in term of ratio of international students are :\n",
    "* Oceania\n",
    "* Europe\n",
    "* North America"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  200 top-ranking universities in www.timeshighereducation.com ([ranking 2018](http://timeshighereducation.com/world-university-rankings/2018/world-ranking)).\n",
    "\n",
    "### Scrapping the web page "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the page of the 2018 Times Higher Eduction ranking, we have found a direct link to a JSON page (given by the URL in the code below). This allowed us to directly load the JSON dataset with the tools provided by pandas, without using Requests or BeautifulSoup.\n",
    "\n",
    "We performed a preprocessing by selecting only the first 200 ranks of the dataset, removing the \"equal\" symbols in front of the rank numbers, renaming the columns and removing the commas in the numbers.\n",
    "\n",
    "Since international student and staff ratios are given, we need to multiply them with the overall number of students to get the total staff and international students count. The number of international staff is however not available in the dataset, nor the region of the university. \n",
    "\n",
    "We also added a command to save the dataset in a file to avoid loading the data from internet at every execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "url='https://www.timeshighereducation.com/sites/default/files/the_data_rankings/world_university_rankings_2018_limit0_369a9045a203e176392b9fb8f8c1cb2a.json'\n",
    "\n",
    "json_dict= requests.get(url).json()\n",
    "raw_data = pd.DataFrame(json_dict['data'])\n",
    "raw_data.columns\n",
    "df_times=raw_data[['name','rank','location','stats_number_students','stats_pc_intl_students','stats_student_staff_ratio']]\n",
    "\n",
    "df_times['rank']=df_times['rank'].str.extract('(\\d+)').astype('int64')\n",
    "df_times = df_times.loc[df_times['rank']<201]\n",
    "df_times.rename(columns={'location':'country','stats_number_students':'students','stats_pc_intl_students':'international students','stats_student_staff_ratio':'staff'},inplace=True)\n",
    "\n",
    "df_times['students'] = df_times['students'].str.replace(',','').astype('int64')\n",
    "\n",
    "df_times['international students'] = df_times['international students'].str.extract('(\\d+)').astype('float64')\n",
    "df_times['international students'] = (df_times['international students']/100)*df_times['students'].astype('float64')\n",
    "df_times['international students'] = df_times['international students'].astype('int64')\n",
    "\n",
    "df_times['staff'] = df_times['staff'].astype('float64')\n",
    "df_times['staff'] = df_times['students'].astype('float64')/df_times['staff']\n",
    "df_times['staff'] = df_times['staff'].astype('int64')\n",
    "\n",
    "df_times.rename(columns={'rank': '(Times) rank', 'title': 'name','staff':'(Times) #faculty members total', 'students':'(Times) #students total','international students':'(Times) #students international' }, inplace=True)\n",
    "df_times.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#USE PICKLE TO SAVE DF\n",
    "filename=\"./data/Times_ranking\"\n",
    "df_times.to_pickle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE PICKLE TO LOAD DF\n",
    "filename=\"./data/Times_ranking\"\n",
    "df_times =pd.read_pickle(filename)\n",
    "df_times.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the QS dataset, we removed the duplicated rank in the list, and verified that they are unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_dup = df_time['(Times) rank'].duplicated()\n",
    "ind_dup = bool_dup[bool_dup == True].index\n",
    "\n",
    "#until no more duplicates\n",
    "for ind in ind_dup :\n",
    "    #add +1 the all the ranks below this duplicate\n",
    "    df_time['(Times) rank'][ind : len(df_time['(Times) rank'])] = df_time['(Times) rank'][ind : len(df_time['(Times) rank']) ] + 1;\n",
    "    \n",
    "print(df_time['(Times) rank'].is_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which are the best universities in term of: (a) ratio between faculty members and students, (b) ratio of international students?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We displayed the ratios between the faculty members and students for the 10 first universities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_time['(Times) faculty members/students']=df_time['(Times) #faculty members total'].astype('float64')/df_time['(Times) #students total']\n",
    "df_time['(Times) international students/ total students']=df_time['(Times) #students international'].astype('float64')/df_time['(Times) #students total']\n",
    "\n",
    "df_plot=df_time[['name','(Times) faculty members/students','(Times) international students/ total students']]\n",
    "df_plot.set_index(['name'],inplace=True) #set name of universities as index for the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot.sort_values('(Times) faculty members/students',ascending=False)['(Times) faculty members/students'].head(10).plot(kind='bar', title='Ratio between faculty members and students')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot.sort_values('(Times) international students/ total students',ascending=False)['(Times) international students/ total students'].head(10).plot(kind='bar', title='Ratio of international students')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the Times ranking, we can see that the three best universities concerning the staff ratio :\n",
    "* Vanderbuilt University\n",
    "* University of Copenhagen\n",
    "* Johns Hopkins University\n",
    "\n",
    "Similarly, the best universities concerning the international students ratio are\n",
    "* London School of Economics and Polotical Science\n",
    "* University of Luxembourg\n",
    "* Imperial College London\n",
    "\n",
    "We can see that it is different from the universities obtained with the QS ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which are the best country in term of: (a) ratio between faculty members and students, (b) ratio of international students?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We averaged the staff and international students ratios for every country present in the Times ranking and display them in a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time.groupby(['country'])['(Times) faculty members/students'].mean().sort_values(ascending=False).plot(kind='bar',title='Average ratio between faculty members and students')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time.groupby(['country'])['(Times) international students/ total students'].mean().sort_values(ascending=False).plot(kind='bar',title='Average ratio of international students')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three coutries were the staff ratio is the highest are:\n",
    "* Denmark\n",
    "* Italy\n",
    "* Russian Federation\n",
    "\n",
    "The countries were the international students ratio is the highest are:\n",
    "* Luxemburg\n",
    "* United Kingdom\n",
    "* Hong Kong\n",
    "\n",
    "In the same way than with the universities, the results are not completely coherents with the QS ranking, even if more or less the same countries are on the top of both lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which are the best region in term of: (a) ratio between faculty members and students, (b) ratio of international students?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the region of each university are not given in the original dataset, we needed to manually define them by sorting the different countries. We averaged the ratios and displayed them, and we also displayed the total number of universities per region, to have a comparisson basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "region = {'Asia':['China','Hong Kong','Japan','Singapore','South Korea','Taiwan']\n",
    "          ,'Europe':['Austria','Belgium','Denmark','Finland','France','Germany','Ireland','Italy','Luxembourg','Netherlands','Norway','Russian Federation','Spain','Sweden','Switzerland','United Kingdom']\n",
    "          ,'North America':['Canada','United States']\n",
    "          ,'Africa':['South Africa']\n",
    "          ,'Oceania':['Australia','New Zealand']}\n",
    "\n",
    "region = { f : i for i in region for f in region[i] }\n",
    "\n",
    "df_time['region'] = df_time['country'].map(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time.groupby(['region'])['(Times) faculty members/students'].mean().sort_values(ascending=False).plot(kind='bar',title='Average ratio between faculty members and students')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time.groupby(['region'])['(Times) international students/ total students'].mean().sort_values(ascending=False).plot(kind='bar',title='Average ratio of international students')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time.groupby(['region'])['(Times) rank'].count().sort_values(ascending=False).plot(kind='bar',title='Number of university per region')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three regions where the staff ratios are the highest are:\n",
    "* North America\n",
    "* Africa\n",
    "* Asia\n",
    "\n",
    "The three regions where the international student ratios are the highest are:\n",
    "* Oceania\n",
    "* Europe\n",
    "* North America\n",
    "\n",
    "We can see that the results are coherent with the ones given by the QS ranking. One important difference is the Africa's average staff ratio, but it can be due to the uncertainty due to the only one relevant university in Africa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging of the two DataFrames using university names. \n",
    "Match universities' names as well as you can, and explain your strategy. Keep track of the original position in both rankings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main problems that was observed was the fact that the Times ranking uses the universties' names expressed in their native language unlike the Qs-Ranking which uses the English name. The first step was therefore to clean our data by translating certain key words and caracters to their English equivalents. A specific translation was made for LMU Munich because its name in the QS-ranking was too distinct from its Times counterpart to be matched. Furthermore, redundant stop words that do not carry any relevant information such as 'The' and 'Of' were removed in order to make the university names more distinct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replace_target = [\"É\",\"é\",\"&\",\"Ludwig-Maximilians-Universität\",\"-\",\"Universite\",\"Universität\",\"Universitaet\",\"Universitat\",\"Technische\",\"Autònoma\",\"München\"]\n",
    "replace_with = [\"E\",\"e\",\"and\",\"LMU\",\" \",\"University\",\"University\",\"University\",\"University\",\"Technical\",\"Autonomous\",\"Munich\"]\n",
    "remove = [\"The \",\"the \",\"Of \",\"of \"]\n",
    "\n",
    "for i in range(len(replace_target)):\n",
    "    df_qs['name'] = df_qs['name'].str.replace(replace_target[i], replace_with[i])\n",
    "    df_times['name'] = df_times['name'].str.replace(replace_target[i], replace_with[i])\n",
    "\n",
    "for word in remove:\n",
    "    df_qs['name'] = df_qs['name'].str.replace(word, \"\")\n",
    "    df_times['name'] = df_times['name'].str.replace(word, \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then define the functions that will be used to match the university names between each other. The first step in each function groups the universities by country. This operation considerably reduces the number of possible false positives during the matching phase. During this matching phase, for each country, we compare the similarity of the universities between themselves. If this similarity is above a predefined threshold, both universities are considered to be a match and their indexes are paired together. These universities are then removed from the symmetric difference datasets. The first function uses the SequenceMatcher similarity. This similarity is defined as 2.0\\*M/T, where T is the total number of elements in both sequences, and M is the number of matches. The second function defines the similarity as the sum of the ratios of the number of common words versus the length of the universities' names (this function was mainly defined in order to compare similar names with different word orders). Both these functions return the dataframes containing the universities that haven't been paired up as well as the list of the paired up indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# match universities according to name similarity\n",
    "def find_common_unmerged(df_qs_out, df_times_out, threshold):\n",
    "    n_duplicates = 0\n",
    "    matched_top = []\n",
    "    matched_time = []\n",
    "    \n",
    "    top_grouped = df_qs_out.groupby('country')\n",
    "    time_grouped = df_times_out.groupby('country')\n",
    "\n",
    "    countries = pd.Series(list(set(df_qs_out['country']).intersection(set(df_times_out['country']))))\n",
    "    \n",
    "    for country in countries:        \n",
    "        unis_top = top_grouped.get_group(name=country)\n",
    "        unis_time = time_grouped.get_group(name=country)     \n",
    "        for name in unis_top['name']:\n",
    "            for compare in unis_time['name']:\n",
    "                score = SequenceMatcher(None, name, compare).ratio()\n",
    "                if score > threshold:\n",
    "                    n_duplicates = n_duplicates + 1\n",
    "                    print('Matched ', name, ' with ', compare, ' with score ',score)\n",
    "                    matched_top.extend(df_qs_out.index[df_qs_out['name'] == name])\n",
    "                    matched_time.extend(df_times_out.index[df_times_out['name'] == compare])\n",
    "                    \n",
    "    print('Number of duplicates found : ', n_duplicates, 'out of ', len(df_qs_out['name']), ' unmerged universities.')\n",
    "    df_qs_out = df_qs_out.drop(matched_top, axis=0)\n",
    "    df_times_out = df_times_out.drop(matched_time, axis=0)\n",
    "    return df_qs_out, df_times_out, matched_top, matched_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# match universities according to common substring\n",
    "def find_common_unmerged_by_substrings(df_qs_out, df_times_out, threshold):\n",
    "    n_duplicates = 0\n",
    "    matched_top = []\n",
    "    matched_time = []\n",
    "    \n",
    "    top_grouped = df_qs_out.groupby('country')\n",
    "    time_grouped = df_times_out.groupby('country')\n",
    "\n",
    "    countries = pd.Series(list(set(df_qs_out['country']).intersection(set(df_times_out['country']))))\n",
    "    \n",
    "    for country in countries:        \n",
    "        unis_top = top_grouped.get_group(name=country)\n",
    "        unis_time = time_grouped.get_group(name=country)     \n",
    "        for name in unis_top['name']:\n",
    "            for compare in unis_time['name']:\n",
    "                top_name_words = name.split()\n",
    "                time_name_words = compare.split()\n",
    "                common = set(top_name_words).intersection( set(time_name_words) )\n",
    "                score = len(common)/len(top_name_words) + len(common)/len(time_name_words)\n",
    "                if score > threshold:\n",
    "                    n_duplicates = n_duplicates + 1\n",
    "                    print('Matched ', name, ' with ', compare, ' with score ',score)\n",
    "                    matched_top.extend(df_qs_out.index[df_qs_out['name'] == name])\n",
    "                    matched_time.extend(df_times_out.index[df_times_out['name'] == compare])\n",
    "                    \n",
    "    print('Number of duplicates found : ', n_duplicates, 'out of ', len(df_qs_out['name']), ' unmerged universities.')\n",
    "    df_qs_out = df_qs_out.drop(matched_top, axis=0)\n",
    "    df_times_out = df_times_out.drop(matched_time, axis=0)\n",
    "    return df_qs_out, df_times_out, matched_top, matched_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run these functions with different thresholds on the subdataframes that contain the symmetric differences of both datasets with respect to names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get universities that weren't merged\n",
    "df_qs_out = df_qs[~df_qs['name'].isin(df_times['name'])]\n",
    "df_times_out = df_times[~df_times['name'].isin(df_qs['name'])]\n",
    "\n",
    "total_matched_top = []\n",
    "total_matched_time = []\n",
    "m_top = []\n",
    "m_time = []\n",
    "\n",
    "# threshold : 0.9\n",
    "df_qs_out, df_times_out, m_top, m_time = find_common_unmerged(df_qs_out, df_times_out, 0.9)\n",
    "total_matched_top.extend(m_top)\n",
    "total_matched_time.extend(m_time)\n",
    "del m_top[:]\n",
    "del m_time[:]\n",
    "\n",
    "# threshold : 0.85\n",
    "df_qs_out, df_times_out, m_top, m_time = find_common_unmerged(df_qs_out, df_times_out, 0.85)\n",
    "total_matched_top.extend(m_top)\n",
    "total_matched_time.extend(m_time)\n",
    "del m_top[:]\n",
    "del m_time[:]\n",
    "\n",
    "# by substrings\n",
    "df_qs_out, df_times_out, m_top, m_time = find_common_unmerged_by_substrings(df_qs_out, df_times_out, 1.4)\n",
    "total_matched_top.extend(m_top)\n",
    "total_matched_time.extend(m_time)\n",
    "del m_top[:]\n",
    "del m_time[:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have detected the university pairs, we can change the Times ranking names to their QS ranking equivalents and merge both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace time names with their top equivalent : \n",
    "for i in range(len(total_matched_time)):\n",
    "    df_times.loc[total_matched_time[i],'name'] = df_qs.loc[total_matched_top[i],'name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_qs, df_times, how='outer')\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory analysis\n",
    "* Find useful insights in the data by performing an exploratory analysis. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df_merged = pd.merge(df_qs, df_times, how='outer')\n",
    "\n",
    "corr_spearman= df_merged.corr(method='spearman')\n",
    "sns.heatmap(corr_spearman)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above we started by plotting the correlation matrix using the Spearman method which is more appropriate for ranking variables not knowing if it's a linear dependence between the variables. Also, using the Spearman method we do not need to make any assumptions on the distribution of the data (cf.([Statistics solutions](http://www.statisticssolutions.com/correlation-pearson-kendall-spearman/)).\n",
    "Let's look at specific parts of this matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_spearman.index\n",
    "corr_qs_qs=corr_spearman[['(QS) rank', '(QS) #faculty members international',\n",
    "       '(QS) #faculty members total', '(QS) #students international',\n",
    "       '(QS) #students total', '(QS) faculty members/students',\n",
    "       '(QS) international students/ total students']].loc[\n",
    "        :'(QS) international students/ total students'];\n",
    "sns.heatmap(corr_qs_qs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix shown above is the correlation matrix of the variables imported or implemented from the [QS ranking 2018](https://www.topuniversities.com/university-rankings/world-university-rankings/2018). Passing the fact that the variables are correlated with themselves, several other expected strong correlations are noticed between:\n",
    "* the number of **total faculty** members and **total students**: this can be explained as the number of professors grows with the number of students;\n",
    "* the number of **international students** and the ratio **international students/students** (as one is used to compute the other);\n",
    "* the number of **international faculty** members and the number of **international students**: this correlation is interesting. We can suppose that the international dimension of a university attracts both international students and professors.\n",
    "* the number of **total students** members and the number of **international students** (as one is part of the other);\n",
    "* the number of **international faculty** members and **total faculty** members (as one is part of the other) and\n",
    "* the number of **international faculty** members and the ratio **international students/students**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_times_times=corr_spearman[['(Times) rank','(Times) #students total', '(Times) #students international',\n",
    "       '(Times) #faculty members total', '(Times) faculty members/students',\n",
    "       '(Times) international students/ total students']].loc['(Times) rank':];\n",
    "sns.heatmap(corr_times_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix shown above is the correlation matrix of the variables imported or implemented from the [Times ranking 2018](http://timeshighereducation.com/world-university-rankings/2018/world-ranking). Passing the fact that the variables are correlated with themselves, several other expected strong correlation  are noticed between:\n",
    "* the number of **total students** members and the number of **international students** (as one is part of the other);\n",
    "* the number of **total faculty** members and **total students**(explainde before);\n",
    "* the number of **international students** and the ratio **international students/students** (as one is used to compute the other)\n",
    "\n",
    "Compare to the QS ranking, we found a stronger correlation between:\n",
    "* the number of  **total faculty** members and and the ratio **faculty members/students** (as one is used to compute the other)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_qs_times=corr_spearman[['(QS) rank','(QS) #students total','(QS) #students international',\n",
    "                              '(QS) #faculty members total',\n",
    "                            '(QS) faculty members/students',\n",
    "                               '(QS) international students/ total students']].loc['(Times) rank':];\n",
    "sns.heatmap(corr_qs_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix shown above is the correlation matrix of the variables imported or implemented from both the QS and Times ranking 2018 web pages. \n",
    "\n",
    "First, we can noticed that corresponding variables in both web sites are not perfectly correlated. This is expected for the rank, as the QS and Times migth not use the same algorithm. Althougth for other variables, a difference between two values is interesting. We can notice that the following variables have different values in both ranking:\n",
    "* the total number of students : correlation between QS and Times = 0.9897;\n",
    "* the number of international students: correlation = 0.9549;\n",
    "* the total number of faculty members: surprisingly low correlation = 0.7437;\n",
    "\n",
    "Both web sites don't have the same data which they're basing their ranking on. The notion of faculty members migth be differently interpreted in both rankings which could explain the low correlation.\n",
    "\n",
    "The matrix shows some \"quasi-diagonality\" and so several other expected strong correlation are noticed between:\n",
    "* the number of **total students** members and the number of **international students** (as one is part of the other);\n",
    "* the number of **total faculty** members and **total students**:(explained before);\n",
    "* the number of **international students** and the ratio **international students/students** (as one is used to compute the other);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the best university"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Can you find the best university taking in consideration both rankings? Explain your approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the best university, we decided to use a Condorcet method (for futher informations: https://en.wikipedia.org/wiki/Condorcet_method) since it has interesting properties. Its basic principle is to elect a winner that beats every other concurrent (here, the universities) in a referundum at the majority of the voters (here, the rankings).\n",
    "\n",
    "We group the univeristies two by two and we perform a vote (each university has a vote from one of the ranking if its score is higher than the other one). The overall score of the university is the number of vote it wins.\n",
    "\n",
    "It has a drawback since many of the univerities are tied in ranking. So we tried to counter this effect by also considering the Shanghai ranking. Both results are shown below, firstly without the Shanghai ranking, and secondly with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parsing the dataset of the Shanghai ranking\n",
    "\n",
    "#basic url\n",
    "universities= requests.get('http://www.shanghairanking.com/ARWU2017.html')\n",
    "soup= BeautifulSoup(universities.text,'html.parser')\n",
    "\n",
    "#find table encapsulatin the wanted information\n",
    "html_shanghai= soup.find_all('table', id=\"UniversityRanking\")\n",
    "#recover the interesting rows (twice for even and odd rows)\n",
    "rank_shanghai_even= html_shanghai[0].find_all('tr', class_=\"bgfd\")\n",
    "rank_shanghai_odd= html_shanghai[0].find_all('tr', class_=\"bgf5\")\n",
    "\n",
    "#list of dictionnaries, one per university\n",
    "uni_list=[]\n",
    "\n",
    "# for each even rows \n",
    "for uni in rank_shanghai_even[0:50]:\n",
    "    #recover: rank, name and url to uni'spage\n",
    "    uni_rank=int(uni.find('td').text);\n",
    "    uni_name=uni.find('a').text\n",
    "    uni_url='http://www.shanghairanking.com/' + uni.find('a')['href']; \n",
    "    #from ulr recover country and region\n",
    "    uni_request= requests.get(uni_url)\n",
    "    uni_soup= BeautifulSoup(uni_request.text,'html.parser')\n",
    "    uni_country= uni_soup.find('div', class_=\"tab_content\").find_all('td')[5].text\n",
    "    uni_region= uni_soup.find('div', class_=\"tab_content\").find_all('td')[3].text\n",
    "    #append as dictionnary in the list\n",
    "    uni_list.append({'name' : uni_name, 'rank Shanghai' : uni_rank,\n",
    "          'country' : uni_country,\n",
    "          'region': uni_region})\n",
    "\n",
    "#same for odd rows   \n",
    "for uni in rank_shanghai_odd[0:50]:\n",
    "    uni_rank=int(uni.find('td').text);\n",
    "    uni_name=uni.find('a').text\n",
    "    uni_url='http://www.shanghairanking.com/' + uni.find('a')['href']; \n",
    "    uni_request= requests.get(uni_url)\n",
    "    uni_soup= BeautifulSoup(uni_request.text,'html.parser')\n",
    "    uni_country= uni_soup.find('div', class_=\"tab_content\").find_all('td')[5].text\n",
    "    uni_region= uni_soup.find('div', class_=\"tab_content\").find_all('td')[3].text\n",
    "    uni_list.append({'name' : uni_name, 'rank Shanghai' : uni_rank,\n",
    "          'country' : uni_country,\n",
    "          'region': uni_region})\n",
    "    \n",
    "#convert list of dictionnary as dataframe\n",
    "df_shanghai=pd.DataFrame(uni_list)\n",
    "#sort rank as we had to do  for even and odd rows separatly\n",
    "df_shanghai=df_shanghai.sort_values('rank Shanghai', ascending=True)\n",
    "\n",
    "df_shanghai.set_index('rank Shanghai')\n",
    "\n",
    "df_shanghai.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_shanghai.index.is_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#USE PICKLE TO SAVE DF (explained before)\n",
    "filename=\"./data/Shanghai_ranking\"\n",
    "df_shanghai.to_pickle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE PICKLE TO LOAD DF (explained before)\n",
    "filename=\"./data/Shanghai_ranking\"\n",
    "df_shanghai =pd.read_pickle(filename)\n",
    "df_shanghai.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we merge the Shanghai dataset with the overall dataset obtained above. It is exactly the same principle with firstly removing and replacing some specific words, then finding common words and strings with also considering the country. There is however an additional step since we need to replace some country name with the one given in the merged dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "country_target=['USA','UK']\n",
    "country_with=['United States','United Kingdom']\n",
    "\n",
    "for i in range(len(country_target)):\n",
    "    df_shanghai['country'] = df_shanghai['country'].str.replace(country_target[i], country_with[i])\n",
    "\n",
    "for i in range(len(replace_target)):\n",
    "    df_shanghai['name'] = df_shanghai['name'].str.replace(replace_target[i], replace_with[i])\n",
    "\n",
    "for word in remove:\n",
    "    df_shanghai['name'] = df_shanghai['name'].str.replace(word, \"\")\n",
    "    \n",
    "df_shanghai_out = df_shanghai[~df_shanghai['name'].isin(df_merged['name'])]\n",
    "df_merged_out = df_merged[~df_merged['name'].isin(df_shanghai['name'])]\n",
    "\n",
    "total_matched_merged = []\n",
    "total_matched_shanghai = []\n",
    "m_merged = []\n",
    "m_shanghai = []\n",
    "\n",
    "# threshold : 0.9\n",
    "df_merged_out, df_shanghai_out, m_merged, m_shanghai = find_common_unmerged(df_merged_out, df_shanghai_out, 0.9)\n",
    "total_matched_merged.extend(m_merged)\n",
    "total_matched_shanghai.extend(m_shanghai)\n",
    "del m_merged[:]\n",
    "del m_shanghai[:]\n",
    "\n",
    "# threshold : 0.85\n",
    "df_merged_out, df_shanghai_out, m_merged, m_shanghai = find_common_unmerged(df_merged_out, df_shanghai_out, 0.85)\n",
    "total_matched_merged.extend(m_merged)\n",
    "total_matched_shanghai.extend(m_shanghai)\n",
    "del m_merged[:]\n",
    "del m_time[:]\n",
    "\n",
    "# by substrings\n",
    "df_merged_out, df_shanghai_out, m_merged, m_shanghai = find_common_unmerged_by_substrings(df_merged_out, df_shanghai_out, 1.49)\n",
    "total_matched_merged.extend(m_merged)\n",
    "total_matched_shanghai.extend(m_shanghai)\n",
    "del m_merged[:]\n",
    "del m_shanghai[:]\n",
    "\n",
    "for i in range(len(total_matched_shanghai)):\n",
    "    df_shanghai.loc[total_matched_shanghai[i],'name'] = df_merged.loc[total_matched_merged[i],'name']\n",
    "\n",
    "df_shanghai=df_shanghai[['name','rank Shanghai']]\n",
    "    \n",
    "df_rank = pd.merge(df_merged, df_shanghai, how='outer')\n",
    "df_rank=df_rank[['name','(Times) rank','(QS) rank','rank Shanghai']]\n",
    "df_rank.columns=['name','TI rank','QS rank','SH rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a function to compare the rank of each pair of university, outputing 1 if the first is higher, or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute_vote(rank_serie):\n",
    "    rank_array = np.array(rank_serie)\n",
    "    rank_array[np.isnan(rank_array)]=201\n",
    "    rank_mat=np.tile(rank_array,(len(rank_array),1))\n",
    "    rank_cmp=np.less_equal(rank_mat,np.transpose(rank_mat)).astype(int)\n",
    "    return rank_cmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TI_cmp=compute_vote(df_rank['TI rank'])\n",
    "SH_cmp=compute_vote(df_rank['SH rank'])\n",
    "QS_cmp=compute_vote(df_rank['QS rank'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vote is then performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_mat=np.greater(QS_cmp+TI_cmp,1).astype(int)\n",
    "df_rank['cond_score']= tot_mat.sum(axis=0)\n",
    "df_rank.sort_values(['cond_score'],ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here the results of the Condorcet method considering only the Times and QS rankings. We can see that we got a unique best and second universities (Stanford and MIT), but the four next have the exact same score, and they can't be differentiated. We can also see that the best university is not the best in the QS ranking nor in the Times ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_mat=np.greater(QS_cmp+TI_cmp+SH_cmp,1.5).astype(int)\n",
    "df_rank['cond_score']= tot_mat.sum(axis=0)\n",
    "df_rank.sort_values(['cond_score'],ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that adding the Shanghai ranking does not change the best university (Stanford) but there are three universities that share the second rank. We can also see that there is another conflict between the eigth and ninth university, so there are not a significant improvement in terms of conflicts. Adding the Shanghai ranking add also lowered the ranked of some universities (such as ETH or Imerial College) which have a poor rank in the Shanghai ranking.\n",
    "\n",
    "We can however say that the world best university according to the three rankings is Stanford."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
