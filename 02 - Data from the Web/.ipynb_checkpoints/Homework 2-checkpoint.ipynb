{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Data from the Web\n",
    "\n",
    "## Deadline\n",
    "Wednesday October 25, 2017 at 11:59PM\n",
    "\n",
    "## Important Notes\n",
    "* Make sure you push on GitHub your Notebook with all the cells already evaluated (i.e., you don't want your colleagues to generate unnecessary Web traffic during the peer review)\n",
    "* Don't forget to add a textual description of your thought process, the assumptions you made, and the solution you plan to implement!\n",
    "* Please write all your comments in English, and use meaningful variable names in your code.\n",
    "\n",
    "## Background\n",
    "In this homework we will extract interesting information from www.topuniversities.com and www.timeshighereducation.com, two platforms that maintain a global ranking of worldwide universities. This ranking is not offered as a downloadable dataset, so you will have to find a way to scrape the information we need!\n",
    "You are not allowed to download manually the entire ranking -- rather you have to understand how the server loads it in your browser. For this task, Postman with the Interceptor extension can help you greatly. We recommend that you watch this [brief tutorial](https://www.youtube.com/watch?v=jBjXVrS8nXs&list=PLM-7VG-sgbtD8qBnGeQM5nvlpqB_ktaLZ&autoplay=1) to understand quickly how to use it.\n",
    "\n",
    "## Assignment\n",
    "* Obtain the 200 top-ranking universities in www.topuniversities.com ([ranking 2018](https://www.topuniversities.com/university-rankings/world-university-rankings/2018)). In particular, extract the following fields for each university: name, rank, country and region, number of faculty members (international and total) and number of students (international and total). Some information is not available in the main list and you have to find them in the [details page](https://www.topuniversities.com/universities/ecole-polytechnique-fÃ©dÃ©rale-de-lausanne-epfl).Store the resulting dataset in a pandas DataFrame and answer the following questions:\n",
    "  * Which are the best universities in term of: (a) ratio between faculty members and students, (b) ratio of international students?\n",
    "\n",
    "  * Answer the previous question aggregating the data by (c) country and (d) region.\n",
    "\n",
    "  Plot your data using bar charts and describe briefly what you observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json \n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# set the default color palette\n",
    "# try other options: 'Blues', sns.cubehelix_palette(8)\n",
    "sns.set_palette('Blues')\n",
    "\n",
    "# Seaborn can also use a context for different purpose\n",
    "# possible values are paper, notebook, talk, and poster\n",
    "sns.set_context(\"notebook\")\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# get name, rank, country and region of the 200 first universities\n",
    "url='https://www.topuniversities.com/sites/default/files/qs-rankings-data/357051.txt?_=1508005996450'\n",
    "universities= requests.get(url).json()['data'][0:200]\n",
    "df_top = pd.DataFrame(universities)\n",
    "df_top = df_top.drop(['cc','core_id','guide', 'logo','score','stars','nid'], axis=1)\n",
    "\n",
    "#list of urls to universities pages\n",
    "urls =list(df_top['url'])\n",
    "\n",
    "# function to get the rest of the needed information on each university page in a dictionnary\n",
    "def get_details(url):\n",
    "    university= requests.get('https://www.topuniversities.com' + url)\n",
    "    soup= BeautifulSoup(university.text,'html.parser')\n",
    "    data= soup.find_all('div', class_= 'faculty-main')\n",
    "    df_top.head()\n",
    "\n",
    "    # number of faculty members international\n",
    "    if(soup.find_all('div', class_ = 'inter faculty') != []):\n",
    "        inter_fac_mem = float(soup.find_all('div', class_ = 'inter faculty')[0].find_all('div', class_ = 'number')[0].string.replace(',',''))\n",
    "    else:\n",
    "        inter_fac_mem = float('nan')\n",
    "        \n",
    "    # number of faculty members total\n",
    "    if(soup.find_all('div', class_ = 'total faculty')!= []):\n",
    "        total_fac_mem = float(soup.find_all('div', class_ = 'total faculty')[0].find_all('div', class_ = 'number')[0].string.replace(',',''))\n",
    "    else:\n",
    "        total_fac_mem = float('nan')\n",
    "        \n",
    "    # number of students international\n",
    "    if(soup.find_all('div', class_ = 'total inter')!= []):\n",
    "        inter_student = float(soup.find_all('div', class_ = 'total inter')[0].find_all('div', class_ = 'number')[0].string.replace(',',''))\n",
    "    else:\n",
    "        inter_student = float('nan')\n",
    "        \n",
    "    # number of students total\n",
    "    if(soup.find_all('div', class_ = 'total student')!= []):\n",
    "        total_student = float(soup.find_all('div', class_ = 'total student')[0].find_all('div', class_ = 'number')[0].string.replace(',',''))\n",
    "    else:\n",
    "        total_student = float('nan')\n",
    "\n",
    "    details = {'url' : url, '#faculty members international (QS)' : inter_fac_mem,\n",
    "          '#faculty members total (QS)' : total_fac_mem,\n",
    "          '#students international (QS)': inter_student,\n",
    "          '#students total (QS)' : total_student}\n",
    "    return details\n",
    "\n",
    "#list of dictionnaries \n",
    "details = []    \n",
    "for url in urls:\n",
    "    details.append(get_details(url))\n",
    "#convert to pd.DataFrame\n",
    "df_top2 = pd.DataFrame(details)\n",
    "\n",
    "#merge the two dataframes with the url\n",
    "df_top= pd.merge(df_top, df_top2, 'outer')\n",
    "df_top.rename(columns={'rank_display': 'QS rank', 'title': 'name'}, inplace=True)\n",
    "df_top = df_top.drop('url', axis=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE PICKLE TO SAVE DF\n",
    "'''\n",
    "filename=\"./data/QS_ranking\"\n",
    "df_qs.to_pickle(filename)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE PICKLE TO LOAD DF\n",
    "\n",
    "filename=\"./data/QS_ranking\"\n",
    "df_top =pd.read_pickle(filename)\n",
    "df_top.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_top['QS rank']=df_top['QS rank'].str.extract('(\\d+)').astype('int64')\n",
    "bool_dup = df_top['QS rank'].duplicated()\n",
    "ind_dup = bool_dup[bool_dup == True].index\n",
    "\n",
    "#until no more duplicates\n",
    "for ind in ind_dup :\n",
    "    #add +1 the all the ranks below this duplicate\n",
    "    df_top['QS rank'][ind : len(df_top['QS rank'])] = df_top['QS rank'][ind : len(df_top['QS rank']) ] + 1;\n",
    "    \n",
    "print(df_top['QS rank'].is_unique)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_top['ratio between faculty members and students'] = df_top['#faculty members total (QS)']/df_top['#students total (QS)']\n",
    "df_top['ratio of international students'] = df_top['#students international (QS)']/df_top['#students total (QS)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratio1 = df_top.sort_values('ratio between faculty members and students', ascending =False)\n",
    "df_ratio1.set_index(['name'],inplace=True)\n",
    "df_ratio1= df_ratio1['ratio between faculty members and students']\n",
    "\n",
    "ax = df_ratio1[0:10].plot.bar()\n",
    "ax.set_xlabel(\"Universities\", fontsize=12)\n",
    "plt.title(\"Ratio between faculty members and students\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratio2 = df_top.sort_values('ratio of international students', ascending =False)\n",
    "df_ratio2.set_index(['name'],inplace=True)\n",
    "df_ratio2= df_ratio2['ratio of international students']\n",
    "\n",
    "ax = df_ratio2[0:10].plot.bar()\n",
    "ax.set_xlabel(\"Universities\", fontsize=12)\n",
    "plt.title(\"Ratio of international students\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_country = df_top.groupby('country').mean()\n",
    "df_region = df_top.groupby('region').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_country_ratio1 = df_country.sort_values('ratio between faculty members and students', ascending =False)\n",
    "df_country_ratio1= df_country_ratio1['ratio between faculty members and students']\n",
    "\n",
    "ax = df_country_ratio1.plot.bar()\n",
    "ax.set_xlabel(\"Country\", fontsize=12)\n",
    "plt.title(\"Ratio between faculty members and students\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country_ratio2 = df_country.sort_values('ratio of international students', ascending =False)\n",
    "df_country_ratio2= df_country_ratio2['ratio of international students']\n",
    "\n",
    "ax = df_country_ratio2.plot.bar()\n",
    "ax.set_xlabel(\"Country\", fontsize=12)\n",
    "plt.title(\"Ratio of international students\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_region_ratio1 = df_region.sort_values('ratio between faculty members and students', ascending =False)\n",
    "df_region_ratio1= df_region_ratio1['ratio between faculty members and students']\n",
    "\n",
    "ax = df_region_ratio1.plot.bar()\n",
    "ax.set_xlabel(\"Region\", fontsize=12)\n",
    "plt.title(\"Ratio between faculty members and students\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_region_ratio2 = df_region.sort_values('ratio of international students', ascending =False)\n",
    "df_region_ratio2= df_region_ratio2['ratio of international students']\n",
    "\n",
    "ax = df_region_ratio2.plot.bar()\n",
    "ax.set_xlabel(\"Region\", fontsize=12)\n",
    "plt.title(\"Ratio of international students\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Obtain the 200 top-ranking universities in www.timeshighereducation.com ([ranking 2018](http://timeshighereducation.com/world-university-rankings/2018/world-ranking)). Repeat the analysis of the previous point and discuss briefly what you observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Merge the two DataFrames created in questions 1 and 2 using university names. Match universities' names as well as you can, and explain your strategy. Keep track of the original position in both rankings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find useful insights in the data by performing an exploratory analysis. Can you find a strong correlation between any pair of variables in the dataset you just created? Example: when a university is strong in its international dimension, can you observe a consistency both for students and faculty members?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Can you find the best university taking in consideration both rankings? Explain your approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hints:\n",
    "- Keep your Notebook clean and don't print the verbose output of the requests if this does not add useful information for the reader.\n",
    "- In case of tie, use the order defined in the webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url='https://www.timeshighereducation.com/sites/default/files/the_data_rankings/world_university_rankings_2018_limit0_369a9045a203e176392b9fb8f8c1cb2a.json'\n",
    "\n",
    "json_dict= requests.get(url).json()\n",
    "raw_data = pd.DataFrame(json_dict['data'])\n",
    "raw_data.columns\n",
    "df_time=raw_data[['name','rank','location','stats_number_students','stats_pc_intl_students','stats_student_staff_ratio']]\n",
    "\n",
    "df_time['rank']=df_time['rank'].str.extract('(\\d+)').astype('int64')\n",
    "df_time = df_time.loc[df_time['rank']<201]\n",
    "df_time.rename(columns={'location':'country','stats_number_students':'students','stats_pc_intl_students':'international students','stats_student_staff_ratio':'staff'},inplace=True)\n",
    "\n",
    "df_time['students'] = df_time['students'].str.replace(',','').astype('int64')\n",
    "\n",
    "df_time['international students'] = df_time['international students'].str.extract('(\\d+)').astype('float64')\n",
    "df_time['international students'] = (df_time['international students']/100)*df_time['students'].astype('float64')\n",
    "df_time['international students'] = df_time['international students'].astype('int64')\n",
    "\n",
    "df_time['staff'] = df_time['staff'].astype('float64')\n",
    "df_time['staff'] = df_time['students'].astype('float64')/df_time['staff']\n",
    "df_time['staff'] = df_time['staff'].astype('int64')\n",
    "\n",
    "df_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time['staff ratio']=df_time['staff'].astype('float64')/df_time['students']\n",
    "barplot = df_time.sort_values('staff ratio',ascending=False)['staff ratio'].head(10).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time['international students ratio']=df_time['international students'].astype('float64')/df_time['students']\n",
    "df_time.sort_values('international students ratio',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time.groupby(['country'])['staff ratio'].mean().sort_values(ascending=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time.groupby(['country'])['international students ratio'].mean().sort_values(ascending=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = {'Asia':['China','Hong Kong','Japan','Singapore','South Korea','Taiwan']\n",
    "          ,'Europe':['Austria','Belgium','Denmark','Finland','France','Germany','Ireland','Italy','Luxembourg','Netherlands','Norway','Russian Federation','Spain','Sweden','Switzerland','United Kingdom']\n",
    "          ,'North America':['Canada','United States']\n",
    "          ,'Africa':['South Africa']\n",
    "          ,'Oceania':['Australia','New Zealand']}\n",
    "\n",
    "region = { f : i for i in region for f in region[i] }\n",
    "\n",
    "df_time['region'] = df_time['country'].map(region)\n",
    "\n",
    "df_time.groupby(['region'])['staff ratio'].mean().sort_values(ascending=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time.groupby(['region'])['international students ratio'].mean().sort_values(ascending=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time.groupby(['region'])['rank'].count().sort_values(ascending=True).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replace_target = [\"É\",\"é\",\"&\",\"Ludwig-Maximilians-Universität\",\"-\",\"Universite\",\"Universität\",\"Universitaet\",\"Universitat\",\"Technische\",\"Autònoma\",\"München\"]\n",
    "replace_with = [\"E\",\"e\",\"and\",\"LMU\",\" \",\"University\",\"University\",\"University\",\"University\",\"Technical\",\"Autonomous\",\"Munich\"]\n",
    "remove = [\"The \",\"the \",\"Of \",\"of \"]\n",
    "\n",
    "for i in range(len(replace_target)):\n",
    "    df_top['name'] = df_top['name'].str.replace(replace_target[i], replace_with[i])\n",
    "    df_time['name'] = df_time['name'].str.replace(replace_target[i], replace_with[i])\n",
    "\n",
    "for word in remove:\n",
    "    df_top['name'] = df_top['name'].str.replace(word, \"\")\n",
    "    df_time['name'] = df_time['name'].str.replace(word, \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get universities that weren't merged\n",
    "df_top_out = df_top[~df_top['name'].isin(df_time['name'])]\n",
    "df_time_out = df_time[~df_time['name'].isin(df_top['name'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# match universities according to name similarity\n",
    "def find_common_unmerged(df_top_out, df_time_out, threshold):\n",
    "    n_duplicates = 0\n",
    "    matched_top = []\n",
    "    matched_time = []\n",
    "    \n",
    "    top_grouped = df_top_out.groupby('country')\n",
    "    time_grouped = df_time_out.groupby('country')\n",
    "\n",
    "    countries = pd.Series(list(set(df_top_out['country']).intersection(set(df_time_out['country']))))\n",
    "    \n",
    "    for country in countries:        \n",
    "        unis_top = top_grouped.get_group(name=country)\n",
    "        unis_time = time_grouped.get_group(name=country)     \n",
    "        for name in unis_top['name']:\n",
    "            for compare in unis_time['name']:\n",
    "                score = SequenceMatcher(None, name, compare).ratio()\n",
    "                if score > threshold:\n",
    "                    n_duplicates = n_duplicates + 1\n",
    "                    print('Matched ', name, ' with ', compare, ' with score ',score)\n",
    "                    matched_top.extend(df_top_out.index[df_top_out['name'] == name])\n",
    "                    matched_time.extend(df_time_out.index[df_time_out['name'] == compare])\n",
    "                    \n",
    "    print('Number of duplicates found : ', n_duplicates, 'out of ', len(df_top_out['name']), ' unmerged universities.')\n",
    "    df_top_out = df_top_out.drop(matched_top, axis=0)\n",
    "    df_time_out = df_time_out.drop(matched_time, axis=0)\n",
    "    return df_top_out, df_time_out, matched_top, matched_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# match universities according to common substring\n",
    "def find_common_unmerged_by_substrings(df_top_out, df_time_out, threshold):\n",
    "    n_duplicates = 0\n",
    "    matched_top = []\n",
    "    matched_time = []\n",
    "    \n",
    "    top_grouped = df_top_out.groupby('country')\n",
    "    time_grouped = df_time_out.groupby('country')\n",
    "\n",
    "    countries = pd.Series(list(set(df_top_out['country']).intersection(set(df_time_out['country']))))\n",
    "    \n",
    "    for country in countries:        \n",
    "        unis_top = top_grouped.get_group(name=country)\n",
    "        unis_time = time_grouped.get_group(name=country)     \n",
    "        for name in unis_top['name']:\n",
    "            for compare in unis_time['name']:\n",
    "                top_name_words = name.split()\n",
    "                time_name_words = compare.split()\n",
    "                common = set(top_name_words).intersection( set(time_name_words) )\n",
    "                score = len(common)/len(top_name_words) + len(common)/len(time_name_words)\n",
    "                if score > threshold:\n",
    "                    n_duplicates = n_duplicates + 1\n",
    "                    print('Matched ', name, ' with ', compare, ' with score ',score)\n",
    "                    matched_top.extend(df_top_out.index[df_top_out['name'] == name])\n",
    "                    matched_time.extend(df_time_out.index[df_time_out['name'] == compare])\n",
    "                    \n",
    "    print('Number of duplicates found : ', n_duplicates, 'out of ', len(df_top_out['name']), ' unmerged universities.')\n",
    "    df_top_out = df_top_out.drop(matched_top, axis=0)\n",
    "    df_time_out = df_time_out.drop(matched_time, axis=0)\n",
    "    return df_top_out, df_time_out, matched_top, matched_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get universities that weren't merged\n",
    "df_top_out = df_top[~df_top['name'].isin(df_time['name'])]\n",
    "df_time_out = df_time[~df_time['name'].isin(df_top['name'])]\n",
    "\n",
    "total_matched_top = []\n",
    "total_matched_time = []\n",
    "m_top = []\n",
    "m_time = []\n",
    "\n",
    "# threshold : 0.9\n",
    "df_top_out, df_time_out, m_top, m_time = find_common_unmerged(df_top_out, df_time_out, 0.9)\n",
    "total_matched_top.extend(m_top)\n",
    "total_matched_time.extend(m_time)\n",
    "del m_top[:]\n",
    "del m_time[:]\n",
    "\n",
    "# threshold : 0.85\n",
    "df_top_out, df_time_out, m_top, m_time = find_common_unmerged(df_top_out, df_time_out, 0.85)\n",
    "total_matched_top.extend(m_top)\n",
    "total_matched_time.extend(m_time)\n",
    "del m_top[:]\n",
    "del m_time[:]\n",
    "\n",
    "# by substrings\n",
    "df_top_out, df_time_out, m_top, m_time = find_common_unmerged_by_substrings(df_top_out, df_time_out, 1.4)\n",
    "total_matched_top.extend(m_top)\n",
    "total_matched_time.extend(m_time)\n",
    "del m_top[:]\n",
    "del m_time[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace time names with their top equivalent : \n",
    "for i in range(len(total_matched_time)):\n",
    "    df_time.loc[total_matched_time[i],'name'] = df_top.loc[total_matched_top[i],'name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#TO CHANGE LATER\n",
    "# merge 'in' universities with same string name\n",
    "\n",
    "df_merged = pd.merge(df_top, df_time, how='outer')\n",
    "\n",
    "print(df_merged.columns)\n",
    "\n",
    "corr_pearson= df_merged.corr('pearson')\n",
    "\n",
    "sns.heatmap(corr_pearson, \n",
    "            xticklabels=corr_pearson.columns.values,\n",
    "            yticklabels=corr_pearson.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " correlation  between\n",
    " \n",
    "* faculty member international, faculty members total\n",
    "* faculty member international, student international\n",
    "* faculty member international, ratio fac/student\n",
    "* faculty member international, international students (time)\n",
    "* student international, ratio international students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_spearman= df_merged.corr(method='spearman')\n",
    "\n",
    "sns.heatmap(corr_spearman, \n",
    "            xticklabels=corr_spearman.columns.values,\n",
    "            yticklabels=corr_spearman.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_kendall= df_merged.corr('kendall')\n",
    "\n",
    "sns.heatmap(corr_kendall, \n",
    "            xticklabels=corr_kendall.columns.values,\n",
    "            yticklabels=corr_kendall.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check= df_merged[[ 'QS rank', '#faculty members total (QS)',\n",
    "        '#students total (QS)',\n",
    "       '#students international (QS)',\n",
    "       'rank','staff', 'students',\n",
    "       'international students']]\n",
    "df_check = df_check.rename(columns={'QS rank': '(QS) rank','#faculty members total (QS)': '(QS) #faculty members total','#students total (QS)':'(QS) #students total', '#students international (QS)': '(QS) #students international' })\n",
    "df_check = df_check.rename(columns={'rank': '(Times) rank ', 'staff': '(Times) #faculty members total','students':'(Times) #students total', 'international students':'(Times) #students international' });\n",
    "corr_diff = df_check.corr();\n",
    "\n",
    "test=corr_diff[['(QS) rank', '(QS) #faculty members total', '(QS) #students total',\n",
    "       '(QS) #students international']].loc[\n",
    "        '(Times) rank ':];\n",
    "sns.heatmap(test)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the best university"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the best university, we decided to use a Condorcet method. We group the univeristies two by two and we perform a vote (each university has a vote from one of the ranking if its score is higher than the other one). The overall score of the university is the number of vote it wins.\n",
    "\n",
    "It has a drawback since it many of the univerities are tied in ranking. So we tried another to counter this effect by also considering the Shanghai ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parsing the dataset of the Shanghai ranking\n",
    "\n",
    "# get name, rank, country and region of the 200 first universities\n",
    "\n",
    "\n",
    "\n",
    "# function to get the rest of the needed information on each university page in a dictionnary\n",
    "'''\n",
    "universities= requests.get('http://www.shanghairanking.com/ARWU2017.html')\n",
    "soup= BeautifulSoup(universities.text,'html.parser')\n",
    "html_shanghai= soup.find_all('table', id=\"UniversityRanking\")\n",
    "rank_shanghai_even= html_shanghai[0].find_all('tr', class_=\"bgfd\")\n",
    "rank_shanghai_odd= html_shanghai[0].find_all('tr', class_=\"bgf5\")\n",
    "\n",
    "uni_list=[]\n",
    "for uni in rank_shanghai_even[0:50]:\n",
    "    uni_rank=int(uni.find('td').text);\n",
    "    uni_name=uni.find('a').text\n",
    "    uni_url='http://www.shanghairanking.com/' + uni.find('a')['href']; \n",
    "    uni_request= requests.get(uni_url)\n",
    "    uni_soup= BeautifulSoup(uni_request.text,'html.parser')\n",
    "    uni_country= uni_soup.find('div', class_=\"tab_content\").find_all('td')[5].text\n",
    "    uni_region= uni_soup.find('div', class_=\"tab_content\").find_all('td')[3].text\n",
    "    uni_list.append({'name' : uni_name, 'rank Shanghai' : uni_rank,\n",
    "          'country' : uni_country,\n",
    "          'region': uni_region})\n",
    "\n",
    "    \n",
    "for uni in rank_shanghai_odd[0:50]:\n",
    "    uni_rank=int(uni.find('td').text);\n",
    "    uni_name=uni.find('a').text\n",
    "    uni_url='http://www.shanghairanking.com/' + uni.find('a')['href']; \n",
    "    uni_request= requests.get(uni_url)\n",
    "    uni_soup= BeautifulSoup(uni_request.text,'html.parser')\n",
    "    uni_country= uni_soup.find('div', class_=\"tab_content\").find_all('td')[5].text\n",
    "    uni_region= uni_soup.find('div', class_=\"tab_content\").find_all('td')[3].text\n",
    "    uni_list.append({'name' : uni_name, 'rank Shanghai' : uni_rank,\n",
    "          'country' : uni_country,\n",
    "          'region': uni_region})\n",
    "\n",
    "df_shanghai=pd.DataFrame(uni_list)\n",
    "\n",
    "df_shanghai=df_shanghai.sort_values('rank Shanghai', ascending=True)\n",
    "df_shanghai.head()\n",
    "\n",
    "df_shanghai.index.is_unique\n",
    "df_shanghai.set_index('rank Shanghai')\n",
    "\n",
    "#USE PICKLE TO SAVE DF\n",
    "filename=\"./data/Shanghai_ranking\"\n",
    "df_shanghai.to_pickle(filename)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset\n",
    "\n",
    "#USE PICKLE TO LOAD DF\n",
    "filename=\"./data/Shanghai_ranking\"\n",
    "df_shanghai =pd.read_pickle(filename)\n",
    "df_shanghai.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_shanghai['name']=df_shanghai['name'].str.lower()\n",
    "#df_shanghai=df_shanghai[['name','rank Shanghai']]\n",
    "\n",
    "\n",
    "\n",
    "country_target=['USA','UK']\n",
    "country_with=['United States','United Kingdom']\n",
    "\n",
    "for i in range(len(country_target)):\n",
    "    df_shanghai['country'] = df_shanghai['country'].str.replace(country_target[i], country_with[i])\n",
    "\n",
    "for i in range(len(replace_target)):\n",
    "    df_shanghai['name'] = df_shanghai['name'].str.replace(replace_target[i], replace_with[i])\n",
    "\n",
    "for word in remove:\n",
    "    df_shanghai['name'] = df_shanghai['name'].str.replace(word, \"\")\n",
    "    \n",
    "df_shanghai_out = df_shanghai[~df_shanghai['name'].isin(df_merged['name'])]\n",
    "df_merged_out = df_merged[~df_merged['name'].isin(df_shanghai['name'])]\n",
    "\n",
    "total_matched_merged = []\n",
    "total_matched_shanghai = []\n",
    "m_merged = []\n",
    "m_shanghai = []\n",
    "\n",
    "# threshold : 0.9\n",
    "df_merged_out, df_shanghai_out, m_merged, m_shanghai = find_common_unmerged(df_merged_out, df_shanghai_out, 0.9)\n",
    "total_matched_merged.extend(m_merged)\n",
    "total_matched_shanghai.extend(m_shanghai)\n",
    "del m_merged[:]\n",
    "del m_shanghai[:]\n",
    "\n",
    "# threshold : 0.85\n",
    "df_merged_out, df_shanghai_out, m_merged, m_shanghai = find_common_unmerged(df_merged_out, df_shanghai_out, 0.85)\n",
    "total_matched_merged.extend(m_merged)\n",
    "total_matched_shanghai.extend(m_shanghai)\n",
    "del m_merged[:]\n",
    "del m_time[:]\n",
    "\n",
    "# by substrings\n",
    "df_merged_out, df_shanghai_out, m_merged, m_shanghai = find_common_unmerged_by_substrings(df_merged_out, df_shanghai_out, 1.49)\n",
    "total_matched_merged.extend(m_merged)\n",
    "total_matched_shanghai.extend(m_shanghai)\n",
    "del m_merged[:]\n",
    "del m_shanghai[:]\n",
    "\n",
    "for i in range(len(total_matched_shanghai)):\n",
    "    df_shanghai.loc[total_matched_shanghai[i],'name'] = df_merged.loc[total_matched_merged[i],'name']\n",
    "\n",
    "df_shanghai=df_shanghai[['name','rank Shanghai']]\n",
    "    \n",
    "df_rank = pd.merge(df_merged, df_shanghai, how='outer')\n",
    "df_rank=df_rank[['name','rank','QS rank','rank Shanghai']]\n",
    "df_rank.columns=['name','TI rank','QS rank','SH rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_vote(rank_serie):\n",
    "    rank_array = np.array(rank_serie)\n",
    "    rank_array[np.isnan(rank_array)]=201\n",
    "    rank_mat=np.tile(rank_array,(len(rank_array),1))\n",
    "    rank_cmp=np.less_equal(rank_mat,np.transpose(rank_mat)).astype(int)\n",
    "    return rank_cmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TI_cmp=compute_vote(df_rank['TI rank'])\n",
    "SH_cmp=compute_vote(df_rank['SH rank'])\n",
    "QS_cmp=compute_vote(df_rank['QS rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_mat=np.greater(QS_cmp+TI_cmp,1).astype(int)\n",
    "df_rank['cond_score']= tot_mat.sum(axis=0)\n",
    "df_rank.sort_values(['cond_score'],ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here the results of the Condorcet method considering only the Times and QS rankings, we can see that we got a unique best university ("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_mat=np.greater(QS_cmp+TI_cmp+SH_cmp,1.5).astype(int)\n",
    "df_rank['cond_score']= tot_mat.sum(axis=0)\n",
    "df_rank.sort_values(['cond_score'],ascending=False).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
