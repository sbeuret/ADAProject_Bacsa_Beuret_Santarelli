{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deadline\n",
    "\n",
    "Wednesday, November 22, 2017, 11:59PM\n",
    "\n",
    "### Important notes\n",
    "\n",
    "When you push your Notebook to GitHub, all the cells must already have been evaluated.\n",
    "Don't forget to add a textual description of your thought process and of any assumptions you've made.\n",
    "Please write all your comments in English, and use meaningful variable names in your code.\n",
    "Question 1: Propensity score matching\n",
    "\n",
    "In this exercise, you will apply propensity score matching, which we discussed in lecture 5 (\"Observational studies\"), in order to draw conclusions from an observational study.\n",
    "\n",
    "We will work with a by-now classic dataset from Robert LaLonde's study \"Evaluating the Econometric Evaluations of Training Programs\" (1986). The study investigated the effect of a job training program (\"National Supported Work Demonstration\") on the real earnings of an individual, a couple of years after completion of the program. Your task is to determine the effectiveness of the \"treatment\" represented by the job training program.\n",
    "\n",
    "### Dataset description\n",
    "\n",
    "treat: 1 if the subject participated in the job training program, 0 otherwise\n",
    "age: the subject's age\n",
    "educ: years of education\n",
    "race: categorical variable with three possible values: Black, Hispanic, or White\n",
    "married: 1 if the subject was married at the time of the training program, 0 otherwise\n",
    "nodegree: 1 if the subject has earned no school degree, 0 otherwise\n",
    "re74: real earnings in 1974 (pre-treatment)\n",
    "re75: real earnings in 1975 (pre-treatment)\n",
    "re78: real earnings in 1978 (outcome)\n",
    "If you want to brush up your knowledge on propensity scores and observational studies, we highly recommend Rosenbaum's excellent book on the \"Design of Observational Studies\". Even just reading the first chapter (18 pages) will help you a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.spatial.distance import cdist\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_raw = pd.read_csv('lalonde.csv')\n",
    "data_raw.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. A naive analysis :\n",
    "\n",
    "Compare the distribution of the outcome variable (re78) between the two groups, using plots and numbers. To summarize and compare the distributions, you may use the techniques we discussed in lectures 4 (\"Read the stats carefully\") and 6 (\"Data visualization\").\n",
    "What might a naive \"researcher\" conclude from this superficial analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to examine these two distributions, we will compare their boxplots and histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_feature(data, feature_name):\n",
    "    \n",
    "    # separate data\n",
    "    control = data[data['treat']==0]\n",
    "    treat = data[data['treat']==1]  \n",
    "    data_feature = data[[feature_name]]\n",
    "    control_feature = control[[feature_name]]\n",
    "    treat_feature = treat[[feature_name]]\n",
    "    \n",
    "    # add boxplot if data is non-binary\n",
    "    if not ((data[feature_name]==0) | (data[feature_name]==1)).all():\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharex=True, sharey=True);\n",
    "        control_feature.boxplot(ax=axes[0])\n",
    "        axes[0].set_title('Control')\n",
    "        treat_feature.boxplot(ax=axes[1])\n",
    "        axes[1].set_title('Treated')\n",
    "    \n",
    "    # plot histograms\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharex=True, sharey=True);\n",
    "    control_feature.plot.hist(ax=axes[0],title='Control - ' + feature_name)\n",
    "    treat_feature.plot.hist(ax=axes[1],title='Treated - ' + feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_feature(data_raw, 're78')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are a lot more unemployed (re=0) subjects in the control group then in the test group. Apart from this fact and ignoring the outliers in the test group, there is no substancial difference in revenue between both groups. Therefore the job training program reduces the likelyhood of being unemployed but does not, on average, affect revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. A closer look at the data:\n",
    "You're not naive, of course (and even if you are, you've learned certain things in ADA), so you aren't content with a superficial analysis such as the above. You're aware of the dangers of observational studies, so you take a closer look at the data before jumping to conclusions.\n",
    "For each feature in the dataset, compare its distribution in the treated group with its distribution in the control group, using plots and numbers. As above, you may use the techniques we discussed in class for summarizing and comparing the distributions.\n",
    "What do you observe? Describe what your observations mean for the conclusions drawn by the naive \"researcher\" from his superficial analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can similarly display and compare the distributions for all features of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_features_comparison(data,skip_features=[]):\n",
    "    feature_names = data.columns[2:]\n",
    "\n",
    "    # for all features\n",
    "    for feature_name in feature_names:\n",
    "        if feature_name not in skip_features:\n",
    "            compare_feature(data,feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_features_comparison(data_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these plots we can point out several problems with the reasoning of the naive \"researcher\". First of all, both groups are not balanced with each other. They do not have the same number of subjects (429 to 185), and many features that could affect revenue (black,hispan,married,nodegree) are not represented in the same proportions. Moreover, we can see that there was actually a big difference in revenue before the training (re74 and re75) between both groups, with the test group being a lot more unemployed/poor in comparison with the control group. Setting aside the fact that both groups are unbalanced, we would conclude that the test group of \"poor\" subjects became as wealthy as the control group after the training, i.e., that the training was very effective. However we can also note that there are many outliers in the boxplots for re74 and re75, suggesting that there are significant divergences within the test group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. A propensity score model :\n",
    "Use logistic regression to estimate propensity scores for all points in the dataset. You may use sklearn to fit the logistic regression model and apply it to each data point to obtain propensity scores:\n",
    "from sklearn import linear_model logistic = linear_model.LogisticRegression() Recall that the propensity score of a data point represents its probability of receiving the treatment, based on its pre-treatment features (in this case, age, education, pre-treatment income, etc.). To brush up on propensity scores, you may read chapter 3.3 of the above-cited book by Rosenbaum or this article.\n",
    "Note: you do not need a train/test split here. Train and apply the model on the entire dataset. If you're wondering why this is the right thing to do in this situation, recall that the propensity score model is not used in order to make predictions about unseen data. Its sole purpose is to balance the dataset across treatment groups. (See p. 74 of Rosenbaum's book for an explanation why slight overfitting is even good for propensity scores. If you want even more information, read this article.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get training data\n",
    "class_name = 'treat'\n",
    "feature_names = data_raw.columns[2:]\n",
    "X = data_raw[feature_names]\n",
    "y = data_raw[class_name]\n",
    "\n",
    "# fit model\n",
    "logistic = LogisticRegression()\n",
    "logistic.fit(X, y)\n",
    "\n",
    "# predict and get propensity scores on training data\n",
    "pred = logistic.predict_proba(X)\n",
    "y_pred = logistic.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to visualize the efficiency of our model, we will use a binary confusion matrix. Such a matrix can be plotted by using the function provided by [Matt Hancock](http://notmatthancock.github.io/2015/10/28/confusion-matrix.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_confusion_matrix(C,class_labels=['0','1']):\n",
    "    \"\"\"\n",
    "    C: ndarray, shape (2,2) as given by scikit-learn confusion_matrix function\n",
    "    class_labels: list of strings, default simply labels 0 and 1.\n",
    "\n",
    "    Draws confusion matrix with associated metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert C.shape == (2,2), \"Confusion matrix should be from binary classification only.\"\n",
    "    \n",
    "    # true negative, false positive, etc...\n",
    "    tn = C[0,0]; fp = C[0,1]; fn = C[1,0]; tp = C[1,1];\n",
    "\n",
    "    NP = fn+tp # Num positive examples\n",
    "    NN = tn+fp # Num negative examples\n",
    "    N  = NP+NN\n",
    "\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax  = fig.add_subplot(111)\n",
    "    ax.imshow(C, interpolation='nearest', cmap=plt.cm.gray)\n",
    "\n",
    "    # Draw the grid boxes\n",
    "    ax.set_xlim(-0.5,2.5)\n",
    "    ax.set_ylim(2.5,-0.5)\n",
    "    ax.plot([-0.5,2.5],[0.5,0.5], '-k', lw=2)\n",
    "    ax.plot([-0.5,2.5],[1.5,1.5], '-k', lw=2)\n",
    "    ax.plot([0.5,0.5],[-0.5,2.5], '-k', lw=2)\n",
    "    ax.plot([1.5,1.5],[-0.5,2.5], '-k', lw=2)\n",
    "\n",
    "    # Set xlabels\n",
    "    ax.set_xlabel('Predicted Label', fontsize=16)\n",
    "    ax.set_xticks([0,1,2])\n",
    "    ax.set_xticklabels(class_labels + [''])\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    ax.xaxis.tick_top()\n",
    "    # These coordinate might require some tinkering. Ditto for y, below.\n",
    "    ax.xaxis.set_label_coords(0.34,1.06)\n",
    "\n",
    "    # Set ylabels\n",
    "    ax.set_ylabel('True Label', fontsize=16, rotation=90)\n",
    "    ax.set_yticklabels(class_labels + [''],rotation=90)\n",
    "    ax.set_yticks([0,1,2])\n",
    "    ax.yaxis.set_label_coords(-0.09,0.65)\n",
    "\n",
    "\n",
    "    # Fill in initial metrics: tp, tn, etc...\n",
    "    ax.text(0,0,\n",
    "            'True Neg: %d\\n(Num Neg: %d)'%(tn,NN),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(0,1,\n",
    "            'False Neg: %d'%fn,\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(1,0,\n",
    "            'False Pos: %d'%fp,\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "\n",
    "    ax.text(1,1,\n",
    "            'True Pos: %d\\n(Num Pos: %d)'%(tp,NP),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    # Fill in secondary metrics: accuracy, true pos rate, etc...\n",
    "    ax.text(2,0,\n",
    "            'False Pos Rate: %.2f'%(fp / (fp+tn+0.)),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(2,1,\n",
    "            'True Pos Rate: %.2f'%(tp / (tp+fn+0.)),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(2,2,\n",
    "            'Accuracy: %.2f'%((tp+tn+0.)/N),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(0,2,\n",
    "            'Neg Pre Val: %.2f'%(1-fn/(fn+tn+0.)),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(1,2,\n",
    "            'Pos Pred Val: %.2f'%(tp/(tp+fp+0.)),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = metrics.confusion_matrix(y,y_pred)\n",
    "show_confusion_matrix(C,class_labels=['Treat','Control'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Balancing the dataset via matching:\n",
    "\n",
    "Use the propensity scores to match each data point from the treated group with exactly one data point from the control group, while ensuring that each data point from the control group is matched with at most one data point from the treated group. (Hint: you may explore the networkx package in Python for predefined matching functions).\n",
    "Your matching should maximize the similarity between matched subjects, as captured by their propensity scores. In other words, the sum (over all matched pairs) of absolute propensity-score differences between the two matched subjects should be minimized.\n",
    "After matching, you have as many treated as you have control subjects. Compare the outcomes (re78) between the two groups (treated and control).\n",
    "Also, compare again the feature-value distributions between the two groups, as you've done in part 2 above, but now only for the matched subjects. What do you observe? Are you closer to being able to draw valid conclusions now than you were before?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform our matching, we will start off by defining a (euclidean) distance matrix where each element is the euclidean distance between the propensity score vectors of a test subject *i* with a control subject *j*. Using this matrix, matching each test subject to his control alter ego is equivalent to solving a classical [assignment problem](https://en.wikipedia.org/wiki/Assignment_problem). This problem can be solved with the scipy.optimize.linear_sum_assignment function which uses the [Hungarian Algorithm](https://en.wikipedia.org/wiki/Hungarian_algorithm), also known as the Munkres or Kuhn-Munkres algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_matching_indices(data,class_name, feature_names):\n",
    "    \n",
    "    # fit logistical model\n",
    "    X = data[feature_names]\n",
    "    y = data[class_name]\n",
    "    logistic = LogisticRegression()\n",
    "    logistic.fit(X, y)\n",
    "    \n",
    "    # predict on classes separatly\n",
    "    control = data[data[class_name]==0]\n",
    "    treat = data[data[class_name]==1]\n",
    "    X_control = control[feature_names]\n",
    "    pred_control = logistic.predict_proba(X_control)\n",
    "    X_treat = treat[feature_names]\n",
    "    pred_treat = logistic.predict_proba(X_treat)\n",
    "    \n",
    "    # Hungarian matching algorithm\n",
    "    dist_matrix = cdist( pred_treat, pred_control )\n",
    "    treat_index, control_index = linear_sum_assignment(dist_matrix)\n",
    "    \n",
    "    # Map matrix index back to sample index\n",
    "    control_id = control['id'].reset_index(drop=True)\n",
    "    treat_id = treat['id']\n",
    "    treat_id_sample = treat_id.iloc[treat_index]\n",
    "    control_id_sample = control_id.iloc[control_index].reset_index(drop=True)\n",
    "    return treat_id_sample.append(control_id_sample).reset_index(drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_id = get_matching_indices(data=data_raw,\n",
    "                                 class_name='treat',\n",
    "                                 feature_names=data_raw.columns[2:])\n",
    "data_sample = data_raw[data_raw['id'].isin(sample_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_features_comparison(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that many of the previously unbalanced features (hispan,married,nodegree) have been balanced out by our matching algorithm. These features did have a significant impact on revenue since our new control group now has a similar re74 and re75 to our test group. However this new result invalidates our previous conclusion : since both the test and the control group saw an increase in revenue between 1975 and 1978, we are now less certain about the efficacy of the job training program. On average, the re78 is higher for the test group, but not significantly enough to conclude that the job training program is actually useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Balancing the groups further\n",
    "Based on your comparison of feature-value distributions from part 4, are you fully satisfied with your matching? Would you say your dataset is sufficiently balanced? If not, in what ways could the \"balanced\" dataset you have obtained still not allow you to draw valid conclusions?\n",
    "Improve your matching by explicitly making sure that you match only subjects that have the same value for the problematic feature. Argue with numbers and plots that the two groups (treated and control) are now better balanced than after part 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still one feature that is still not balanced between both groups : black, which may be one of the most important factors when it comes to [income inequality in the United States](https://en.wikipedia.org/wiki/Racial_wage_gap_in_the_United_States). Furthermore, the boxplots for re74, re75 and re78 still have many outliers, suggesting that there is a division within our dataset. In order to verify our concerns, we will redo our matching/comparison on separate datasets for blacks and non-blacks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For blacks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_black = data_raw[data_raw['black']==1]\n",
    "names_of_features = data_raw.columns[2:].tolist()\n",
    "names_of_features.remove('black')\n",
    "names_of_features.remove('hispan')\n",
    "\n",
    "sample_id = get_matching_indices(data=data_black,\n",
    "                                 class_name='treat',\n",
    "                                 feature_names=names_of_features)\n",
    "data_sample_black = data_black[data_black['id'].isin(sample_id)]\n",
    "display_features_comparison(data_sample_black,skip_features=['hispan','black'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For non-blacks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_black = data_raw[data_raw['black']==0]\n",
    "names_of_features = data_raw.columns[2:].tolist()\n",
    "names_of_features.remove('black')\n",
    "\n",
    "sample_id = get_matching_indices(data=data_no_black,\n",
    "                                 class_name='treat',\n",
    "                                 feature_names=names_of_features)\n",
    "data_sample_no_black = data_no_black[data_no_black['id'].isin(sample_id)]\n",
    "display_features_comparison(data_sample_no_black,skip_features=['black'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are indeed large discrepencies between the revenues of both subgroups. We will therefore draw different conclusions for both groups : \n",
    "\n",
    "- For blacks, the feature distributions for both control and test groups are quite close which allow us to draw strong conclusions. Compared to non-blacks, blacks are much more likely to be unemployed and on average earn much less, though there are many exceptions to this rule (many outliers in boxplots). When comparing re74, re75, and re78, we can observe that the revenue of both groups has grown almost identically. We can therefore conclude that for blacks, the job training program had no effect.\n",
    "\n",
    "\n",
    "- For non-blacks, there are still discrepencies between the feature distributions for both control and test groups, meaning that any conclusion made from these results must be taken with a grain of salt. If we were to only look at the re74 and re78, we would deduce that the more unemployed/poor test groups in 1974 has caught up in terms of wealth by 1978 with the control group, i.e., that the training program has been highly efficient. However, for strange reasons, there is a high disparity between the re74 and re75 for both the control and the test group. Because of these inconsistencies, it is not possible for us to conclude that the training program was actually successful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Possible external factors :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inconsistencies in our results may have been caused by factors that have not been taken into account by our dataset. These factors could include macroeconomic trends that occured during the study. Ideally, the study should have been conducted over a period of stable growth/unemployment. This, however, was not the case. After the 1973 oil crisis, the United States entered a period of [recession](https://en.wikipedia.org/wiki/1973%E2%80%9375_recession) between 1973 and 1975, which caused wages to drop and unemployement to rise. This was when the values for revenue before the job training program were reported. The US would only fully recover in 1978, when economic growth would peak at 5.6% (fig:1). This was when the values for revenue after the job training program were reported. Given such drastic changes in the economy, and based on the evolution of wages coupled with inflation during the period of the study (fig:2 and 3), it is not possible to draw conclusions from this study (payment is required to get data for wages and inflation, therefore you will need to indulge our PNGs ;) )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get GDP values :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp = pd.read_csv('real_gdp_rate_1972_to_1980.csv')\n",
    "gdp = gdp.set_index('DATE', drop=True)\n",
    "gdp_values = gdp.values.flatten().tolist()\n",
    "gdp_dates = gdp.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Unemployment values :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment = pd.read_excel('unemployment_1972_to_1980.xlsx',skiprows=[0,1,2,3,4,5,6,7,8,9])\n",
    "unemployment = unemployment.rename(columns=unemployment.iloc[0])\n",
    "unemployment = unemployment.drop(unemployment.index[0])\n",
    "unemployment = unemployment.stack()\n",
    "\n",
    "unemployment_values = []\n",
    "for i in range(1,9):\n",
    "    unemployment_values.extend(unemployment[i].values[1:].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(14,7))\n",
    "ax=fig.add_subplot(111, label=\"GDP\")\n",
    "ax2=fig.add_subplot(111, label=\"Unemployment\", frame_on=False)\n",
    "\n",
    "ax.plot(gdp_dates,gdp_values, color=\"C0\")\n",
    "ax.set_xlabel(\"dates\", color=\"C0\")\n",
    "ax.set_ylabel(\"GDP rate in %\", color=\"C0\")\n",
    "ax.tick_params(axis='x', colors=\"C0\", rotation=90)\n",
    "ax.tick_params(axis='y', colors=\"C0\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1])\n",
    "\n",
    "ax2.plot(unemployment_values, color=\"C1\")\n",
    "ax2.get_xaxis().set_visible(False)\n",
    "ax2.yaxis.tick_right()\n",
    "ax2.set_ylabel('Unemployment rate in %', color=\"C1\")       \n",
    "ax2.yaxis.set_label_position('right') \n",
    "ax2.tick_params(axis='y', colors=\"C1\")\n",
    "\n",
    "plt.title('Fig 1 : GDP rate and Unemployment between 1972 and 1980')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fig 2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"wages_1972_to_1980.PNG\",width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fig 3 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"inflation_1972_to_1980.PNG\",width=800)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
