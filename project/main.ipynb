{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import codecs\n",
    "import folium\n",
    "from scipy import sparse, stats, spatial\n",
    "import scipy.sparse.linalg\n",
    "%matplotlib inline\n",
    "#np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load election data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_party_data(path):\n",
    "    data=pd.read_excel(path)\n",
    "    data.drop([data.columns[0],data.columns[2],data.columns[3],data.columns[4]],1,inplace=True)\n",
    "    data.drop([0,1],0,inplace=True)\n",
    "    data.columns=['commune','party','percentage']\n",
    "    data=data.ffill()\n",
    "    data=data.groupby(['commune','party']).sum().unstack('party')\n",
    "    data2=data.reset_index()['percentage']\n",
    "    data2['commune']=data.reset_index()['commune']\n",
    "    return data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "data=load_party_data('data/partis_12prem_vote_2015.xlsx')\n",
    "data2=load_party_data('data/partis_12der_vote_2015.xlsx')\n",
    "\n",
    "#take only commune\n",
    "data=data[data['commune'].str.startswith('......')]\n",
    "data2=data2[data2['commune'].str.startswith('......')]\n",
    "data['commune']=data['commune'].str[7:]\n",
    "data2['commune']=data2['commune'].str[7:]\n",
    "\n",
    "#merge datasets\n",
    "data=pd.merge(data,data2,on='commune')\n",
    "\n",
    "#replace non-available parties with 0\n",
    "data.loc[:, data.columns != 'commune']=data.loc[:, data.columns != 'commune'].replace('...','0')\n",
    "\n",
    "#remove data from comming from correspondancies\n",
    "data=data[(data['commune'].str[:2]==(data['commune'].str.upper()).str[:2]) & (data['commune'].str[2]=='-') ==False]\n",
    "data.loc[:, data.columns != 'commune']=data.loc[:, data.columns != 'commune']\n",
    "data=data.set_index('commune')\n",
    "data.index=data.index.str.replace(re.escape(' (Urne commune)'),'')\n",
    "data=data.astype(float)\n",
    "data=data.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "general=pd.read_excel('data/general_2015.xlsx')\n",
    "general=general[['Unnamed: 1','Unnamed: 9']]\n",
    "general.drop([0,1],0,inplace=True)\n",
    "general.columns=['commune','voters']\n",
    "#general=general[general['commune'].str.startswith('......')]\n",
    "general=general[general['commune'].str.startswith('......',na=False)]\n",
    "general['commune']=general['commune'].str[7:]\n",
    "general=general[(general['commune'].str[:2]==(general['commune'].str.upper()).str[:2]) & (general['commune'].str[2]=='-') ==False]\n",
    "general['voters']=general['voters'].replace('...','0')\n",
    "general['voters']=general['voters'].astype(int)\n",
    "general=general.set_index('commune')\n",
    "general=general.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2=data.drop([col for col, val in data.sum().iteritems() if val==0],axis=1)\n",
    "data_tot=data2.as_matrix()\n",
    "#data_tot=data_tot/data_tot.sum(1)[:,None]\n",
    "data_tot\n",
    "data.index.to_series()[data_tot.sum(1)==0]\n",
    "\n",
    "commune_with_no_vote=(data_tot.sum(1)==0)\n",
    "\n",
    "data_tot[commune_with_no_vote==False]=np.divide(data_tot[commune_with_no_vote==False],data_tot[commune_with_no_vote==False].sum(1)[:,None])\n",
    "\n",
    "data_tab=data_tot[commune_with_no_vote==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pop_tot=np.squeeze(general.as_matrix())\n",
    "pop_tab=pop_tot[commune_with_no_vote==False]\n",
    "#plt.hist(pop_tab,bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fusion=[['Valbirse','Malleray','Bévilard','Pontenet'],\n",
    "        ['Terre di Pedemonte','Cavigliano','Tegna','Verscio'],\n",
    "        ['Val-de-Charmey','Charmey','Cerniat (FR)'],\n",
    "        ['Sauge','Frinvillier','Plagne','Vauffelin'],\n",
    "        ['Buchegg','Aetigkofen','Aetingen','Bibern (SO)','Brügglen','Gossliwil','Hessigkofen','Küttigkofen','Kyburg-Buchegg','Mühledorf (SO)','Tscheppach'],\n",
    "        ['Domleschg','Almens','Paspels','Pratval','Rodels','Tomils'],\n",
    "        ['Petit-Val','Châtelat','Monible','Sornetan','Souboz'],\n",
    "        ['Ilanz/Glion','Castrisch','Ilanz','Ladir','Luven','Pitasch','Riein','Ruschein','Schnaus','Sevgein','Duvin','Pigniu','Rueun','Siat'],\n",
    "        ['Péry-La Heutte','Péry','La Heutte'],\n",
    "        ['Calanca','Arvigo','Braggio','Cauco','Selma'],\n",
    "        ['Bettmeralp','Betten','Martisberg'],\n",
    "        ['Arzier-Le Muids','Arzier'],\n",
    "        ['Schinznach','Schinznach-Dorf','Oberflachs'],\n",
    "        ['Albula/Alvra','Alvaschein','Mon','Stierva','Tiefencastel','Alvaneu','Brienz/Brinzauls','Surava'],\n",
    "        ['Bussigny','Bussigny-près-Lausanne'],\n",
    "        ['Stocken-Höfen','Niederstocken','Oberstocken','Höfen'],\n",
    "        ['Plateau de Diesse','Diesse','Lamboing','Prêles'],\n",
    "        ['Mendrisio','Besazio','Ligornetto','Meride'],\n",
    "        ['Lugano','Bogno','Cadro','Carona','Certara','Cimadera','Sonvico','Valcolla'],\n",
    "        ['Bauma','Sternenberg'],\n",
    "        ['Scuol','Guarda','Ardez','Tarasp','Ftan','Sent'],\n",
    "        ['Jegenstorf','Scheunen','Münchringen'],\n",
    "        ['Fraubrunnen','Büren zum Hof','Etzelkofen','Grafenried','Limpach','Mülchi','Schalunen','Zauggenried'],\n",
    "        ['Murten','Staatswald Galm'],\n",
    "        ['Grafschaft','Kommunanz Reckingen-Gluringen/Grafschaft'],\n",
    "        ['Cadenazzo','Comunanza Cadenazzo/Monteceneri'],\n",
    "        ['Wiesendangen','Bertschikon'],\n",
    "        ['Innertkirchen','Gadmen'],\n",
    "        ['Endingen','Unterendingen'],\n",
    "        ['Uttigen','Kienersrüti'],\n",
    "        ['Bremgarten (AG)','Bremgarten','Hermetschwil-Staffeln'],\n",
    "        ['Zernez','Lavin','Susch'],\n",
    "        ['Oberdiessbach','Bleiken bei Oberdiessbach'],\n",
    "        ['Vals','St. Martin']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize election results :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read topojson data\n",
    "json_data_gemeinden = json.load(codecs.open('data/gemeinden.topo.json', 'r', 'utf-8-sig'))\n",
    "json_data_kantone = json.load(codecs.open('data/kantone.topo.json', 'r', 'utf-8-sig'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display only borders\n",
    "center_coord = [46.8011111,8.2266667]\n",
    "m_swiss = folium.Map(location=center_coord,\n",
    "            tiles='cartodbpositron',           \n",
    "            zoom_start=7.5)\n",
    "\n",
    "folium.TopoJson(json_data_gemeinden,'objects.gemeinden',name='communes',style_function=lambda feature: {\n",
    "        'color': 'blue',\n",
    "        'fillOpacity':0.0,\n",
    "        'weight': 2}).add_to(m_swiss)\n",
    "\n",
    "folium.TopoJson(json_data_kantone,'objects.kantone',name='cantons',style_function=lambda feature: {\n",
    "        'color': 'red',\n",
    "        'fillOpacity':0.0,\n",
    "        'weight': 2}).add_to(m_swiss)\n",
    "folium.LayerControl().add_to(m_swiss)\n",
    "m_swiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose party to display\n",
    "party = 'SVP/UDC'\n",
    "\n",
    "# get election results for selected party\n",
    "n_communes = len(json_data_gemeinden['objects']['gemeinden']['geometries'])\n",
    "party_values = []\n",
    "\n",
    "for i in range(n_communes):\n",
    "    json_name = json_data_gemeinden['objects']['gemeinden']['geometries'][i]['properties']['GMDNAME']\n",
    "    dfval = data[data.index==json_name][party].values.tolist()\n",
    "    if not dfval:\n",
    "        dfval=[0]  \n",
    "    party_values.append([json_name,dfval[0]])\n",
    "    \n",
    "labels = ['Name','Score']\n",
    "party_df = pd.DataFrame(data=party_values,columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build and display folium map of election results\n",
    "center_coord = [46.8011111,8.2266667]\n",
    "m_swiss = folium.Map(location=center_coord,\n",
    "            tiles='cartodbpositron',           \n",
    "            zoom_start=7.5)\n",
    "\n",
    "serie = party_df.set_index('Name')['Score']\n",
    "\n",
    "scale = list(np.linspace(0.,serie.max(),6))\n",
    "\n",
    "m_swiss.choropleth(geo_data=json_data_gemeinden, topojson='objects.gemeinden', \n",
    "    data=serie,\n",
    "    key_on='feature.properties.GMDNAME',\n",
    "    threshold_scale=scale,\n",
    "    fill_color='YlOrRd', fill_opacity=0.6, line_opacity=0.3,\n",
    "    highlight = True)\n",
    "\n",
    "folium.TopoJson(json_data_kantone,'objects.kantone',name='cantons',style_function=lambda feature: {\n",
    "        'color': 'blue',\n",
    "        'fillOpacity':0.0,\n",
    "        'weight': 2}).add_to(m_swiss)\n",
    "\n",
    "m_swiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop parties with no votes\n",
    "data.drop([col for col, val in data.sum().iteritems() if val==0],axis=1)\n",
    "features = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate our distance map, we will use the L1-norm. Similarly to signal processing, the L1-norm enables us to embed a \"sharpness\" property when partitioning our graph, rather than the L2-norm (euclidean) which has a tendancy to smoothen out divisions instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# construct adjacency map based on L1-norm distance map with gaussian kernel\n",
    "distances = spatial.distance.squareform(spatial.distance.pdist(features,'minkowski', p=1.))\n",
    "kernel_width = distances.mean()\n",
    "weights = np.exp(np.divide(-np.square(distances),kernel_width**2))\n",
    "np.fill_diagonal(weights,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(weights, axes):\n",
    "    axes[0].spy(weights)\n",
    "    axes[1].hist(weights[weights > 0].reshape(-1), bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparsify weights matrix using nearest neighbors\n",
    "fix, axes = plt.subplots(2, 2, figsize=(17, 8))\n",
    "plot(weights, axes[:, 0])\n",
    "\n",
    "NEIGHBORS = 350\n",
    "\n",
    "for i in range(weights.shape[0]):\n",
    "    idx = weights[i,:].argsort()[:-NEIGHBORS]\n",
    "    weights[i,idx] = 0\n",
    "    weights[idx,i] = 0\n",
    "\n",
    "plot(weights, axes[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the weights of our nodes exhibit a power tail distribution. This indicates that our graph is not random, and that it can instead be clustered into different classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute normalized laplacian\n",
    "degrees = np.sum(weights,axis=0)\n",
    "laplacian = np.diag(degrees**-0.5) @ (np.diag(degrees) - weights) @ np.diag(degrees**-0.5)\n",
    "plt.spy(laplacian);\n",
    "laplacian = sparse.csr_matrix(laplacian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate eigenvectors (features)\n",
    "eigenvalues, eigenvectors = sparse.linalg.eigsh(A=laplacian,k=10,which='SM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, axes = plt.subplots(nrows=5, ncols=5, figsize=(17, 8))\n",
    "for i in range(1,6):\n",
    "    for j in range(1,6):\n",
    "        if i == 1:\n",
    "            axes[i-1,j-1].set_xlabel('eig' + str(j))\n",
    "            axes[i-1,j-1].xaxis.set_label_position('top') \n",
    "        if j == 1:\n",
    "            axes[i-1,j-1].set_ylabel('eig' + str(i))\n",
    "        x = eigenvectors[:,i]\n",
    "        y = eigenvectors[:,j]\n",
    "        labels = np.sign(x)\n",
    "        axes[i-1,j-1].scatter(x, y, c=labels, cmap='RdBu', alpha=0.5)\n",
    "        \n",
    "fix.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define classes and labels\n",
    "class_1 = (eigenvectors[:,1] >= 0).astype(int)\n",
    "class_2 = (eigenvectors[:,2] >= 0).astype(int)\n",
    "class_3 = (eigenvectors[:,3] >= 0).astype(int)\n",
    "labels = class_1 * 2**2 + class_2 * 2 + class_3\n",
    "series = pd.Series(labels, index=data.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot classes\n",
    "center_coord = [46.8011111,8.2266667]\n",
    "m_swiss = folium.Map(location=center_coord,\n",
    "            tiles='cartodbpositron',           \n",
    "            zoom_start=7.5)\n",
    "\n",
    "scale = list(np.linspace(0.,series.max(),6))\n",
    "\n",
    "m_swiss.choropleth(geo_data=json_data_gemeinden, topojson='objects.gemeinden', \n",
    "    data=series,\n",
    "    key_on='feature.properties.GMDNAME',\n",
    "    threshold_scale=scale,\n",
    "    fill_color='YlOrRd', fill_opacity=0.6, line_opacity=0.3,\n",
    "    highlight = True)\n",
    "\n",
    "folium.TopoJson(json_data_kantone,'objects.kantone',name='cantons',style_function=lambda feature: {\n",
    "        'color': 'blue',\n",
    "        'fillOpacity':0.0,\n",
    "        'weight': 2}).add_to(m_swiss)\n",
    "\n",
    "m_swiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# crete_random_data(N=number of parties,M=number of communes)\n",
    "# for each commune, create a random percentage distribution for the list of parties\n",
    "\n",
    "def create_random_data(N,M):\n",
    "    ptab = 2 * np.random.rand(N)\n",
    "    tab = ptab[:,np.newaxis] + np.random.normal(0.0,0.5,(N,M))\n",
    "    #tab = 1 * np.random.rand(N, M)\n",
    "    tab = np.exp(tab)\n",
    "    stab = np.sum(tab, 0)\n",
    "    tab = tab / stab[None, :]\n",
    "    return tab\n",
    "\n",
    "#create_random_pop(M=number of communes)\n",
    "#for each commune create a random population\n",
    "\n",
    "def create_random_pop(M):\n",
    "    #pop = np.random.randint(1000,size=M)\n",
    "    pop = np.floor((np.random.pareto(1, size=M))*500)\n",
    "    return pop\n",
    "\n",
    "#vote(data=table with the percentage of each party for each canton,Nrepr=number of represent to elec for each canton)\n",
    "#compute the vote to get the number of representants per cantons (check the highest percentage give it a representant,\n",
    "#substract 1/Nrepr and repeat).\n",
    "\n",
    "def vote(data,Nrepr):\n",
    "    repr=np.zeros(data.shape)\n",
    "    for i in range(Nrepr):\n",
    "        maxi=np.argmax(data,0)\n",
    "\n",
    "        k = (maxi[:,None]==np.arange(data.shape[0])).transpose()\n",
    "        repr = repr + k.astype(int)\n",
    "        data[k]=data[k]-(1/Nrepr)\n",
    "\n",
    "    nan_tab = np.isnan(data)\n",
    "    repr[nan_tab]=0\n",
    "\n",
    "    return repr\n",
    "\n",
    "#compute_tab_K(tab=percentage of vote by parties and commune,pop=population of each commune,K_index=canton of each commune)\n",
    "#aggregate the vote per cantons\n",
    "\n",
    "def compute_tab_K(tab,pop,K_index,K):\n",
    "    K_full = (K_index[:, None] == np.arange(K))\n",
    "    tab_mult_by_pop = pop * tab\n",
    "    tab_sum = np.matmul(tab_mult_by_pop, K_full.astype(float))\n",
    "    K_sum = (pop * K_full.transpose()).sum(1)\n",
    "\n",
    "    final_tab = tab_sum/K_sum\n",
    "    #nan_tab = np.isnan(final_tab)\n",
    "    #final_tab[nan_tab]=0\n",
    "\n",
    "    return final_tab\n",
    "\n",
    "#reproduce(K_index1=canton for each commune (one repartition),K_index1=canton for each commune (another repartition))\n",
    "#create a new repartition given two (select randomly one element in each repartition)\n",
    "\n",
    "def reproduce_K(K_index1,K_index2):\n",
    "    choice=np.random.randint(2,size=K_index1.shape)\n",
    "    K_tot=np.stack([K_index1,K_index2],axis=1)\n",
    "    return(K_tot[choice[:,None]==np.arange(2)])\n",
    "\n",
    "#mute(K_index=canton per commune (one repartition),prob=probability to mute)\n",
    "#change to a commune to a random canton with probability prob\n",
    "\n",
    "def mute_K(K_index,K,prob):\n",
    "    choice=np.random.randint(K,size=K_index.shape)\n",
    "    change=(np.random.rand(K_index.shape[0])<prob).astype(int)\n",
    "    K_tot = np.stack([K_index, choice], axis=1);\n",
    "    return (K_tot[change[:,None]==np.arange(2)])\n",
    "\n",
    "#get_new_generation(K_index_list=list of repartition,N_parents=number of parents,\n",
    "#                   N_child_per_couple=number of generated children for two parents,\n",
    "#                   prob=mute probability,K=number of canton)\n",
    "#given a list of parent distribution, compute N_child_per_couple*N_parents\"(N_parents-1) new distributions\n",
    "\n",
    "def get_new_generation(K_index_list,N_parents,N_child_per_couple,prob,K):\n",
    "\n",
    "    child_list=[]\n",
    "\n",
    "    for i in range(N_parents):\n",
    "        for j in range(i+1,N_parents):\n",
    "            for k in range(N_child_per_couple):\n",
    "                child=reproduce_K(K_index_list[i],K_index_list[j])\n",
    "                child=mute_K(child,K,prob)\n",
    "                child_list.append(child)\n",
    "    return child_list\n",
    "\n",
    "#compute_loss(child_list=a list of distribution,tab=percentage for each party for each commune, pop=population for each commune,\n",
    "#             N_repr=number of representat per canton)\n",
    "#compute the loss (difference between real opinion and represented opinion, can add other terms)\n",
    "\n",
    "def compute_loss(child_list,tab,pop,N_repr):\n",
    "    loss=[]\n",
    "    rloss=[]\n",
    "    for child in child_list:\n",
    "        repr=vote(compute_tab_K(tab,pop,child,K),N_repr)\n",
    "        repr_percent=(repr/(repr.sum().sum())).sum(1)\n",
    "        rloss.append(np.square(repr_percent-ground_truth).sum())\n",
    "        loss.append(np.square(repr_percent-ground_truth).sum()) \n",
    "    return loss, rloss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=============== variable generation parameters ===============\n",
    "N=15 #number of categories (parties)\n",
    "M=2200 #number of item (communes)\n",
    "#==============================================================\n",
    "\n",
    "#=============== model parameters =============================\n",
    "K=26 #number of cantons\n",
    "N_repr=2 #number of representant per canton\n",
    "#==============================================================\n",
    "\n",
    "#=============== optimization parameters =============\n",
    "N_parents=10\n",
    "N_iter=1000\n",
    "child_per_couple=2\n",
    "mute_probability=0.04\n",
    "#====================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_tab = create_random_data(N,M)\n",
    "main_pop = create_random_pop(M)\n",
    "ground_truth = (main_pop * main_tab).sum(1)/main_pop.sum()\n",
    "\n",
    "print(main_pop.sum())\n",
    "print(main_tab.sum().sum())\n",
    "print(ground_truth)\n",
    "\n",
    "\n",
    "parent_list = []\n",
    "for i in range(N_parents):\n",
    "    parent_list.append(np.random.randint(K,size=M))\n",
    "\n",
    "minloss=[]\n",
    "avgloss=[]\n",
    "\n",
    "for iter in range(N_iter):\n",
    "    child_list = get_new_generation(parent_list,N_parents,child_per_couple,mute_probability,K)\n",
    "\n",
    "    loss=np.array(compute_loss(child_list,main_tab,main_pop,N_repr))\n",
    "    minloss.append(loss.min())\n",
    "    avgloss.append(loss.mean())\n",
    "    idx = loss.argsort()[:N_parents]\n",
    "    parent_list=[child_list[i] for i in idx]\n",
    "\n",
    "\n",
    "print(minloss[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(np.arange(0,N_iter,1),np.array(minloss))\n",
    "plt.plot(np.arange(0,N_iter,1),np.array(avgloss))\n",
    "plt.show()\n",
    "plt.hist(main_pop,bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=============== model parameters =============================\n",
    "K=2 #number of cantons\n",
    "N_repr=2 #number of representant per canton\n",
    "#==============================================================\n",
    "\n",
    "#=============== optimization parameters =============\n",
    "N_parents=15\n",
    "N_iter=100\n",
    "child_per_couple=2\n",
    "mute_probability=0.005\n",
    "#=====================================================\n",
    "\n",
    "ground_truth = (pop_tab * np.transpose(data_tab)).sum(1)/pop_tab.sum()\n",
    "\n",
    "parent_list = []\n",
    "for i in range(N_parents):\n",
    "    parent_list.append(np.random.randint(K,size=pop_tab.shape[0]))\n",
    "\n",
    "\n",
    "minloss=[]\n",
    "avgloss=[]\n",
    "\n",
    "\n",
    "minrloss=[]\n",
    "avgrloss=[]\n",
    "\n",
    "for iter in range(N_iter):\n",
    "    child_list = get_new_generation(parent_list,N_parents,child_per_couple,mute_probability,K)\n",
    "    \n",
    "    loss,rloss = compute_loss(child_list,np.transpose(data_tab),pop_tab,N_repr)\n",
    "    loss=np.array(loss)\n",
    "    rloss=np.array(rloss)\n",
    "    minloss.append(loss.min())\n",
    "    avgloss.append(loss.mean())\n",
    "    minrloss.append(rloss.min())\n",
    "    avgrloss.append(rloss.mean())\n",
    "    \n",
    "    idx = loss.argsort()[:N_parents]\n",
    "    parent_list=[child_list[i] for i in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(np.arange(0,N_iter,1),np.array(minrloss))\n",
    "plt.plot(np.arange(0,N_iter,1),np.array(avgrloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parent_list[0]\n",
    "lol=parent_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.linalg.norm((lol[:, None] == np.arange(K)).sum(0)-(lol[:, None] == np.arange(K)).sum(0).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
