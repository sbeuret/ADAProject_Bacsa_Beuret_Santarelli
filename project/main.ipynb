{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import codecs\n",
    "import folium\n",
    "from scipy import sparse, stats, spatial\n",
    "import scipy.sparse.linalg\n",
    "%matplotlib inline\n",
    "#np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load election data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_party_data(path):\n",
    "    data=pd.read_excel(path)\n",
    "    data.drop([data.columns[0],data.columns[2],data.columns[3],data.columns[4]],1,inplace=True)\n",
    "    data.drop([0,1],0,inplace=True)\n",
    "    data.columns=['commune','party','percentage']\n",
    "    data=data.ffill()\n",
    "    data=data.groupby(['commune','party']).sum().unstack('party')\n",
    "    data2=data.reset_index()['percentage']\n",
    "    data2['commune']=data.reset_index()['commune']\n",
    "    return data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load party data\n",
    "data=load_party_data('data/partis_12prem_vote_2015.xlsx')\n",
    "data2=load_party_data('data/partis_12der_vote_2015.xlsx')\n",
    "\n",
    "#take only commune (not districts)\n",
    "data=data[data['commune'].str.startswith('......')]\n",
    "data2=data2[data2['commune'].str.startswith('......')]\n",
    "data['commune']=data['commune'].str[7:]\n",
    "data2['commune']=data2['commune'].str[7:]\n",
    "\n",
    "#merge the two datasets\n",
    "data=pd.merge(data,data2,on='commune')\n",
    "\n",
    "#replace non-available parties with 0\n",
    "data.loc[:, data.columns != 'commune']=data.loc[:, data.columns != 'commune'].replace('...','0')\n",
    "\n",
    "#remove data coming from correspondancy votes\n",
    "data=data[(data['commune'].str[:2]==(data['commune'].str.upper()).str[:2]) & (data['commune'].str[2]=='-') ==False]\n",
    "data.loc[:, data.columns != 'commune']=data.loc[:, data.columns != 'commune']\n",
    "data=data.set_index('commune')\n",
    "data.index=data.index.str.replace(re.escape(' (Urne commune)'),'')\n",
    "data=data.astype(float)\n",
    "data=data.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load election metadata and rename columns\n",
    "general=pd.read_excel('data/general_2015.xlsx')\n",
    "general=general[['Unnamed: 1','Unnamed: 9']]\n",
    "general.drop([0,1],0,inplace=True)\n",
    "general.columns=['commune','voters']\n",
    "\n",
    "#take only the voter per commune (not districts) and remove data coming from correspondancy votes\n",
    "general=general[general['commune'].str.startswith('......',na=False)]\n",
    "general['commune']=general['commune'].str[7:]\n",
    "general=general[(general['commune'].str[:2]==(general['commune'].str.upper()).str[:2]) & (general['commune'].str[2]=='-') ==False]\n",
    "general['voters']=general['voters'].replace('...','0')\n",
    "general['voters']=general['voters'].astype(int)\n",
    "general=general.set_index('commune')\n",
    "general=general.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prepare data for genetic algorithm\n",
    "data2=data.drop([col for col, val in data.sum().iteritems() if val==0],axis=1)\n",
    "data_tot=data2.as_matrix()\n",
    "data.index.to_series()[data_tot.sum(1)==0]\n",
    "data_tot=data_tot/100\n",
    "\n",
    "\n",
    "#remove communes with no votes\n",
    "commune_with_no_vote=(data_tot.sum(1)==0)\n",
    "data_tot[commune_with_no_vote,-1]=1\n",
    "#data_tot[commune_with_no_vote==False]=np.divide(data_tot[commune_with_no_vote==False],data_tot[commune_with_no_vote==False].sum(1)[:,None])\n",
    "#data_tab=data_tot[commune_with_no_vote==False]\n",
    "data_tab=data_tot\n",
    "#data[commune_with_no_vote==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prepare voter data for genetic algorithm\n",
    "pop_tot=np.squeeze(general.as_matrix())\n",
    "#pop_tab=pop_tot[commune_with_no_vote==False]\n",
    "pop_tab=pop_tot\n",
    "pop_tab[commune_with_no_vote]=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We defined here a list of merged communes between 2013 and 2015, with the resulting commune in the first position\n",
    "\n",
    "\n",
    "fusion=[['Valbirse','Malleray','Bévilard','Pontenet'],\n",
    "        ['Terre di Pedemonte','Cavigliano','Tegna','Verscio'],\n",
    "        ['Val-de-Charmey','Charmey','Cerniat (FR)'],\n",
    "        ['Sauge','Frinvillier','Plagne','Vauffelin'],\n",
    "        ['Buchegg','Aetigkofen','Aetingen','Bibern (SO)','Brügglen','Gossliwil','Hessigkofen','Küttigkofen','Kyburg-Buchegg','Mühledorf (SO)','Tscheppach'],\n",
    "        ['Domleschg','Almens','Paspels','Pratval','Rodels','Tomils'],\n",
    "        ['Petit-Val','Châtelat','Monible','Sornetan','Souboz'],\n",
    "        ['Ilanz/Glion','Castrisch','Ilanz','Ladir','Luven','Pitasch','Riein','Ruschein','Schnaus','Sevgein','Duvin','Pigniu','Rueun','Siat'],\n",
    "        ['Péry-La Heutte','Péry','La Heutte'],\n",
    "        ['Calanca','Arvigo','Braggio','Cauco','Selma'],\n",
    "        ['Bettmeralp','Betten','Martisberg'],\n",
    "        ['Arzier-Le Muids','Arzier'],\n",
    "        ['Schinznach','Schinznach-Dorf','Oberflachs'],\n",
    "        ['Albula/Alvra','Alvaschein','Mon','Stierva','Tiefencastel','Alvaneu','Brienz/Brinzauls','Surava'],\n",
    "        ['Bussigny','Bussigny-près-Lausanne'],\n",
    "        ['Stocken-Höfen','Niederstocken','Oberstocken','Höfen'],\n",
    "        ['Plateau de Diesse','Diesse','Lamboing','Prêles'],\n",
    "        ['Mendrisio','Besazio','Ligornetto','Meride'],\n",
    "        ['Lugano','Bogno','Cadro','Carona','Certara','Cimadera','Sonvico','Valcolla'],\n",
    "        ['Bauma','Sternenberg'],\n",
    "        ['Scuol','Guarda','Ardez','Tarasp','Ftan','Sent'],\n",
    "        ['Jegenstorf','Scheunen','Münchringen'],\n",
    "        ['Fraubrunnen','Büren zum Hof','Etzelkofen','Grafenried','Limpach','Mülchi','Schalunen','Zauggenried'],\n",
    "        ['Murten','Staatswald Galm'],\n",
    "        ['Grafschaft','Kommunanz Reckingen-Gluringen/Grafschaft'],\n",
    "        ['Cadenazzo','Comunanza Cadenazzo/Monteceneri'],\n",
    "        ['Wiesendangen','Bertschikon'],\n",
    "        ['Innertkirchen','Gadmen'],\n",
    "        ['Endingen','Unterendingen'],\n",
    "        ['Uttigen','Kienersrüti'],\n",
    "        ['Bremgarten (AG)','Bremgarten','Hermetschwil-Staffeln'],\n",
    "        ['Zernez','Lavin','Susch'],\n",
    "        ['Oberdiessbach','Bleiken bei Oberdiessbach'],\n",
    "        ['Vals','St. Martin']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating CSVs for website :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create CSV files for election results :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2.to_csv('data/results_2015.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize election results :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read topojson data\n",
    "json_data_gemeinden = json.load(codecs.open('data/gemeinden.topo.json', 'r', 'utf-8-sig'))\n",
    "json_data_kantone = json.load(codecs.open('data/kantone.topo.json', 'r', 'utf-8-sig'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#since the topojson for visualisation dates back to 2013, some old municipipalities in the topojson now unified are\n",
    "#missing in the dataset. Since it's complicated to find a topojson up to date, we will duplicate the data from the \n",
    "#unified municipalities to the old ones.\n",
    "\n",
    "#list of the old munipalities fron the topjson\n",
    "with open('data/gemeinden.topo.json') as f:\n",
    "    muni=json.load(f)\n",
    "    \n",
    "s = pd.DataFrame(muni['objects']['gemeinden']['geometries'])\n",
    "properties=s['properties'].values\n",
    "municipalities_topo = pd.DataFrame(list(properties))['GMDNAME']\n",
    "#municipalities_topo\n",
    "\n",
    "#list of the new municipalities from dataset\n",
    "#municipalities_data=data['commune']\n",
    "municipalities_data = pd.Series(data.index.values)\n",
    "municipalities_data.head()\n",
    "\n",
    "#diff of both: municipalities in top no it dataset\n",
    "diff_ind=~municipalities_topo.isin(municipalities_data) \n",
    "municipalities_diff= municipalities_topo[diff_ind]\n",
    "\n",
    "#for all diff munip create new row in data:\n",
    "#diff_df=pd.DataFrame(columns = data.columns, index= municipalities_diff)\n",
    "for old_munip in municipalities_diff:\n",
    "    #find corresponding new munip\n",
    "    for i in fusion:\n",
    "        for j in i:\n",
    "            if old_munip == j:\n",
    "                new_munip=i[0]\n",
    "                #copy row from data with corresponding to new munip\n",
    "                new_row=data.ix[new_munip]\n",
    "                new_row = pd.DataFrame(new_row.rename(old_munip)).T\n",
    "                data=data.append(new_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display only borders\n",
    "center_coord = [46.8011111,8.2266667]\n",
    "m_swiss = folium.Map(location=center_coord,\n",
    "            tiles='cartodbpositron',           \n",
    "            zoom_start=7.5)\n",
    "\n",
    "folium.TopoJson(json_data_gemeinden,'objects.gemeinden',name='communes',style_function=lambda feature: {\n",
    "        'color': 'blue',\n",
    "        'fillOpacity':0.0,\n",
    "        'weight': 2}).add_to(m_swiss)\n",
    "\n",
    "folium.TopoJson(json_data_kantone,'objects.kantone',name='cantons',style_function=lambda feature: {\n",
    "        'color': 'red',\n",
    "        'fillOpacity':0.0,\n",
    "        'weight': 2}).add_to(m_swiss)\n",
    "folium.LayerControl().add_to(m_swiss)\n",
    "m_swiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the [map](https://kbacsa.github.io/swiss_border.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "party_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose party to display\n",
    "party = 'SP/PS'\n",
    "\n",
    "# get election results for selected party\n",
    "n_communes = len(json_data_gemeinden['objects']['gemeinden']['geometries'])\n",
    "party_values = []\n",
    "\n",
    "for i in range(n_communes):\n",
    "    json_name = json_data_gemeinden['objects']['gemeinden']['geometries'][i]['properties']['GMDNAME']\n",
    "    dfval = data[data.index==json_name][party].values.tolist()\n",
    "    if not dfval:\n",
    "        dfval=[0]  \n",
    "    party_values.append([json_name,dfval[0]])\n",
    "    \n",
    "labels = ['Name','Score']\n",
    "party_df = pd.DataFrame(data=party_values,columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build and display folium map of election results\n",
    "center_coord = [46.8011111,8.2266667]\n",
    "m_swiss = folium.Map(location=center_coord,\n",
    "            tiles='cartodbpositron',           \n",
    "            zoom_start=7.5)\n",
    "\n",
    "serie = party_df.set_index('Name')['Score']\n",
    "\n",
    "scale = list(np.linspace(0.,serie.max(),6))\n",
    "\n",
    "m_swiss.choropleth(geo_data=json_data_gemeinden, topojson='objects.gemeinden', \n",
    "    data=serie,\n",
    "    key_on='feature.properties.GMDNAME',\n",
    "    threshold_scale=scale,\n",
    "    fill_color='YlOrRd', fill_opacity=0.6, line_opacity=0.3,\n",
    "    highlight = True)\n",
    "\n",
    "folium.TopoJson(json_data_kantone,'objects.kantone',name='cantons',style_function=lambda feature: {\n",
    "        'color': 'blue',\n",
    "        'fillOpacity':0.0,\n",
    "        'weight': 2}).add_to(m_swiss)\n",
    "\n",
    "m_swiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the [map](https://kbacsa.github.io/swiss_votes_SVP_2015.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop parties with no votes\n",
    "#data.drop([col for col, val in data.sum().iteritems() if val==0],axis=1)\n",
    "features = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate our distance map, we will use the L1-norm. Similarly to signal processing, the L1-norm enables us to embed a \"sharpness\" property when partitioning our graph, rather than the L2-norm (euclidean) which has a tendancy to smoothen out divisions instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# construct adjacency map based on L1-norm distance map with gaussian kernel\n",
    "distances = spatial.distance.squareform(spatial.distance.pdist(features,'minkowski', p=1.))\n",
    "kernel_width = distances.mean()\n",
    "weights = np.exp(np.divide(-np.square(distances),kernel_width**2))\n",
    "np.fill_diagonal(weights,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(weights, axes):\n",
    "    axes[0].spy(weights)\n",
    "    axes[1].hist(weights[weights > 0].reshape(-1), bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sparsify weights matrix using nearest neighbors\n",
    "fix, axes = plt.subplots(2, 2, figsize=(17, 8))\n",
    "plot(weights, axes[:, 0])\n",
    "\n",
    "NEIGHBORS = 350\n",
    "\n",
    "for i in range(weights.shape[0]):\n",
    "    idx = weights[i,:].argsort()[:-NEIGHBORS]\n",
    "    weights[i,idx] = 0\n",
    "    weights[idx,i] = 0\n",
    "\n",
    "plot(weights, axes[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the weights of our nodes exhibit a power tail distribution. This indicates that our graph is not random, and that it can instead be clustered into different classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute normalized laplacian\n",
    "degrees = np.sum(weights,axis=0)\n",
    "laplacian = np.diag(degrees**-0.5) @ (np.diag(degrees) - weights) @ np.diag(degrees**-0.5)\n",
    "plt.spy(laplacian);\n",
    "laplacian = sparse.csr_matrix(laplacian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate eigenvectors (features)\n",
    "eigenvalues, eigenvectors = sparse.linalg.eigsh(A=laplacian,k=10,which='SM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fix, axes = plt.subplots(nrows=5, ncols=5, figsize=(17, 8))\n",
    "for i in range(1,6):\n",
    "    for j in range(1,6):\n",
    "        if i == 1:\n",
    "            axes[i-1,j-1].set_xlabel('eig' + str(j))\n",
    "            axes[i-1,j-1].xaxis.set_label_position('top') \n",
    "        if j == 1:\n",
    "            axes[i-1,j-1].set_ylabel('eig' + str(i))\n",
    "        x = eigenvectors[:,i]\n",
    "        y = eigenvectors[:,j]\n",
    "        labels = np.sign(x)\n",
    "        axes[i-1,j-1].scatter(x, y, c=labels, cmap='RdBu', alpha=0.5)\n",
    "        \n",
    "fix.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define classes and labels\n",
    "class_1 = (eigenvectors[:,1] >= 0).astype(int)\n",
    "class_2 = (eigenvectors[:,2] >= 0).astype(int)\n",
    "class_3 = (eigenvectors[:,3] >= 0).astype(int)\n",
    "labels = class_1 * 2**2 + class_2 * 2 + class_3\n",
    "series = pd.Series(labels, index=data.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmap = matplotlib.cm.get_cmap('Spectral')\n",
    "color_map = cmap(np.arange(0,1,1/26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def color(class_label, color_map): \n",
    "    return  {\n",
    "    'fillOpacity': 0.5,\n",
    "    'weight': 0.5,\n",
    "    'fillColor': '#%02x%02x%02x' % tuple((256 * color_map[class_label,:3]).astype(int)),\n",
    "    'color': '#%02x%02x%02x' % tuple((256 * color_map[class_label,:3]).astype(int))\n",
    "     }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def style_function(data):    \n",
    "    if data['properties']['GMDNAME'] in series.index:\n",
    "        class_label = series[series.index == data['properties']['GMDNAME']][0]\n",
    "        return color(class_label, color_map)\n",
    "    \n",
    "    else:\n",
    "        return  {\n",
    "        'fillOpacity': 0.5,\n",
    "        'weight': 0.5,\n",
    "        'fillColor': '#%02x%02x%02x' % tuple((256 * color_map[0,:3]).astype(int)),\n",
    "        'color': '#%02x%02x%02x' % tuple((256 * color_map[0,:3]).astype(int))\n",
    "         } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_cantons(series, json_data_gemeinden, json_data_kantone):\n",
    "    center_coord = [46.8011111,8.2266667]\n",
    "    cantons_map = folium.Map(location=center_coord,\n",
    "                tiles='cartodbpositron',           \n",
    "                zoom_start=7.5)\n",
    "\n",
    "    folium.TopoJson(json_data_gemeinden,'objects.gemeinden',name='gemeiden',\n",
    "                    style_function=style_function).add_to(cantons_map)\n",
    "\n",
    "    folium.TopoJson(json_data_kantone,'objects.kantone',name='cantons',style_function=lambda feature: {\n",
    "            'color': 'blue',\n",
    "            'fillOpacity':0.0,\n",
    "            'weight': 2}).add_to(cantons_map)\n",
    "    \n",
    "    return cantons_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "series.to_csv(path='data/spectral_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot classes\n",
    "center_coord = [46.8011111,8.2266667]\n",
    "m_swiss = folium.Map(location=center_coord,\n",
    "            tiles='cartodbpositron',           \n",
    "            zoom_start=7.5)\n",
    "\n",
    "scale = list(np.linspace(0.,series.max(),6))\n",
    "\n",
    "m_swiss.choropleth(geo_data=json_data_gemeinden, topojson='objects.gemeinden', \n",
    "    data=series,\n",
    "    key_on='feature.properties.GMDNAME',\n",
    "    threshold_scale=scale,\n",
    "    fill_color='YlOrRd', fill_opacity=0.6, line_opacity=0.3,\n",
    "    highlight = True)\n",
    "\n",
    "folium.TopoJson(json_data_kantone,'objects.kantone',name='cantons',style_function=lambda feature: {\n",
    "        'color': 'blue',\n",
    "        'fillOpacity':0.0,\n",
    "        'weight': 2}).add_to(m_swiss)\n",
    "\n",
    "m_swiss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the [map](https://kbacsa.github.io/spectral_clustering.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_to_right = [6,14,10,1,7,13,3,5,2,4,0,8,13,12,11,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange(target_list, order):\n",
    "    return [ target_list[i] for i in order]\n",
    "\n",
    "def generate_parliament_json(file_name, ids, seats, order):\n",
    "    names = ['Conservative Democratic Party',\n",
    "        'Christian Social Party',\n",
    "        'Christian Democratic People\\'s Party',\n",
    "        'Evangelical People\\'s Party',\n",
    "        'The Liberals',\n",
    "        'Green Liberal Party',\n",
    "        'Swiss Party of Labour',\n",
    "        'Social Democratic Party',\n",
    "        'Swiss People\\'s Party',\n",
    "        'Federal Democratic Union',\n",
    "        'Green Party',\n",
    "        'Ticino League',\n",
    "        'Romandy Citizens\\' Movement',\n",
    "        'Swiss Democrats',\n",
    "        'solidaritéS',\n",
    "        'Others']\n",
    "\n",
    "    ids = rearrange(ids,order)\n",
    "    seats = rearrange(seats,order)\n",
    "    names = rearrange(names,order)\n",
    "    \n",
    "    d = {'id': ids, \n",
    "         'legend' : names,\n",
    "         'name' : names,\n",
    "         'seats': seats}\n",
    "    \n",
    "    parliament = pd.DataFrame(data=d)\n",
    "\n",
    "    with open('data/' + file_name +'.json', 'w') as outfile:\n",
    "        json.dump(json.JSONDecoder().decode(parliament.to_json(orient='records')), outfile, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrange seats from most progressive to most conservative\n",
    "left_to_right = [6,14,10,1,7,13,3,5,2,4,0,8,13,12,11,15]\n",
    "\n",
    "# national council\n",
    "real_seats = [7,0,28,2,33,7,1,43,65,0,11,2,0,0,0,1]\n",
    "generate_parliament_json('parliament_2015_national',data2.columns.values,real_seats,left_to_right)\n",
    "\n",
    "# council of states\n",
    "real_seats = [1,0,13,0,13,0,0,12,5,0,1,0,0,0,0,1]\n",
    "generate_parliament_json('parliament_2015_states',data2.columns.values,real_seats,left_to_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# crete_random_data(N=number of parties,M=number of communes)\n",
    "# for each commune, create a random percentage distribution for the list of parties\n",
    "\n",
    "def create_random_data(N,M):\n",
    "    ptab = 2 * np.random.rand(N)\n",
    "    tab = ptab[:,np.newaxis] + np.random.normal(0.0,0.5,(N,M))\n",
    "    #tab = 1 * np.random.rand(N, M)\n",
    "    tab = np.exp(tab)\n",
    "    stab = np.sum(tab, 0)\n",
    "    tab = tab / stab[None, :]\n",
    "    return tab\n",
    "\n",
    "#create_random_pop(M=number of communes)\n",
    "#for each commune create a random population\n",
    "\n",
    "def create_random_pop(M):\n",
    "    #pop = np.random.randint(1000,size=M)\n",
    "    pop = np.floor((np.random.pareto(1, size=M))*500)\n",
    "    return pop\n",
    "\n",
    "#vote(data=table with the percentage of each party for each canton,Nrepr=number of represent to elec for each canton)\n",
    "#compute the vote to get the number of representants per cantons (check the highest percentage give it a representant,\n",
    "#substract 1/Nrepr and repeat).\n",
    "\n",
    "def vote(data,Nrepr):\n",
    "    rep=np.zeros(data.shape)\n",
    "    for i in range(Nrepr):\n",
    "        maxi=np.argmax(data,0)\n",
    "\n",
    "        k = (maxi[:,None]==np.arange(data.shape[0])).transpose()\n",
    "        rep = rep + k.astype(int)\n",
    "        data[k]=data[k]-(1/Nrepr)\n",
    "\n",
    "    nan_tab = np.isnan(data)\n",
    "    rep[nan_tab]=0\n",
    "\n",
    "    return rep\n",
    "\n",
    "#compute_tab_K(tab=percentage of vote by parties and commune,pop=population of each commune,K_index=canton of each commune)\n",
    "#aggregate the vote per cantons\n",
    "\n",
    "def compute_tab_K(tab,pop,K_index,K):\n",
    "    K_full = (K_index[:, None] == np.arange(K))\n",
    "    tab_mult_by_pop = pop * tab\n",
    "    tab_sum = np.matmul(tab_mult_by_pop, K_full.astype(float))\n",
    "    K_sum = (pop * K_full.transpose()).sum(1)\n",
    "\n",
    "    final_tab = tab_sum/K_sum\n",
    "    #nan_tab = np.isnan(final_tab)\n",
    "    #final_tab[nan_tab]=0\n",
    "\n",
    "    return final_tab\n",
    "\n",
    "#reproduce(K_index1=canton for each commune (one repartition),K_index1=canton for each commune (another repartition))\n",
    "#create a new repartition given two (select randomly one element in each repartition)\n",
    "\n",
    "def reproduce_K(K_index1,K_index2):\n",
    "    choice=np.random.randint(2,size=K_index1.shape)\n",
    "    K_tot=np.stack([K_index1,K_index2],axis=1)\n",
    "    return(K_tot[choice[:,None]==np.arange(2)])\n",
    "\n",
    "#mute(K_index=canton per commune (one repartition),prob=probability to mute)\n",
    "#change to a commune to a random canton with probability prob\n",
    "\n",
    "def mute_K(K_index,K,prob):\n",
    "    choice=np.random.randint(K,size=K_index.shape)\n",
    "    change=(np.random.rand(K_index.shape[0])<prob).astype(int)\n",
    "    K_tot = np.stack([K_index, choice], axis=1);\n",
    "    return (K_tot[change[:,None]==np.arange(2)])\n",
    "\n",
    "#get_new_generation(K_index_list=list of repartition,N_parents=number of parents,\n",
    "#                   N_child_per_couple=number of generated children for two parents,\n",
    "#                   prob=mute probability,K=number of canton)\n",
    "#given a list of parent distribution, compute N_child_per_couple*N_parents\"(N_parents-1) new distributions\n",
    "\n",
    "def get_new_generation(K_index_list,N_parents,N_child_per_couple,prob,K):\n",
    "\n",
    "    child_list=[]\n",
    "\n",
    "    for i in range(N_parents):\n",
    "        for j in range(i+1,N_parents):\n",
    "            for k in range(N_child_per_couple):\n",
    "                child=reproduce_K(K_index_list[i],K_index_list[j])\n",
    "                child=mute_K(child,K,prob)\n",
    "                child_list.append(child)\n",
    "    return child_list\n",
    "\n",
    "def graph_loss(graph,rep,K):\n",
    "    rep_one_hot = np.zeros((rep.shape[0],K))\n",
    "    rep_one_hot[np.arange(rep.shape[0]),rep]=1\n",
    "    x=np.matmul(graph,rep_one_hot)/np.sum(graph,axis=1)[:,None]\n",
    "    return x[np.arange(rep.shape[0]),rep]\n",
    "\n",
    "#compute_loss(child_list=a list of distribution,tab=percentage for each party for each commune, pop=population for each commune,\n",
    "#             N_repr=number of representat per canton)\n",
    "#compute the loss (difference between real opinion and represented opinion, can add other terms)\n",
    "\n",
    "def compute_loss(child_list,tab,pop,N_repr):\n",
    "    loss=[]\n",
    "    rloss=[]\n",
    "    for child in child_list:\n",
    "        repr=vote(compute_tab_K(tab,pop,child,K),N_repr)\n",
    "        repr_percent=(repr/(repr.sum().sum())).sum(1)\n",
    "        rloss.append(np.square(repr_percent-ground_truth).sum())\n",
    "        loss.append(np.square(repr_percent-ground_truth).sum()) \n",
    "    return loss, rloss\n",
    "\n",
    "\n",
    "def compute_graph_loss(child_list,tab,pop,N_repr,graph,K,lambda_graph):\n",
    "    loss=[]\n",
    "    rloss=[]\n",
    "    for child in child_list:\n",
    "        repr=vote(compute_tab_K(tab,pop,child,K),N_repr)\n",
    "        repr_percent=(repr/(repr.sum().sum())).sum(1)\n",
    "        rloss.append(np.square(repr_percent-ground_truth).sum())\n",
    "        loss.append(np.square(repr_percent-ground_truth).sum() - lambda_graph * np.log(np.mean(graph_loss(graph,child,K)))) \n",
    "    return loss, rloss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=============== variable generation parameters ===============\n",
    "N=15 #number of categories (parties)\n",
    "M=2200 #number of item (communes)\n",
    "#==============================================================\n",
    "\n",
    "#=============== model parameters =============================\n",
    "K=26 #number of cantons\n",
    "N_repr=2 #number of representant per canton\n",
    "#==============================================================\n",
    "\n",
    "#=============== optimization parameters =============\n",
    "N_parents=10\n",
    "N_iter=1000\n",
    "child_per_couple=2\n",
    "mute_probability=0.04\n",
    "#====================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=============== model parameters =============================\n",
    "K=2 #number of cantons\n",
    "N_repr=2 #number of representant per canton\n",
    "#==============================================================\n",
    "\n",
    "#=============== optimization parameters =============\n",
    "N_parents=15\n",
    "N_iter=100\n",
    "child_per_couple=2\n",
    "mute_probability=0.005\n",
    "#=====================================================\n",
    "\n",
    "#compute the global political opinion\n",
    "ground_truth = (pop_tab * np.transpose(data_tab)).sum(1)/pop_tab.sum()\n",
    "#initailize parent list\n",
    "parent_list = []\n",
    "for i in range(N_parents):\n",
    "    parent_list.append(np.random.randint(K,size=pop_tab.shape[0]))\n",
    "\n",
    "minloss=[]\n",
    "avgloss=[]\n",
    "\n",
    "minrloss=[]\n",
    "avgrloss=[]\n",
    "#perform optimization\n",
    "for iter in range(N_iter):\n",
    "    child_list = get_new_generation(parent_list,N_parents,child_per_couple,mute_probability,K)\n",
    "    \n",
    "    loss,rloss = compute_loss(child_list,np.transpose(data_tab),pop_tab,N_repr)\n",
    "    loss=np.array(loss)\n",
    "    rloss=np.array(rloss)\n",
    "    minloss.append(loss.min())\n",
    "    avgloss.append(loss.mean())\n",
    "    minrloss.append(rloss.min())\n",
    "    avgrloss.append(rloss.mean())\n",
    "    \n",
    "    idx = loss.argsort()[:N_parents]\n",
    "    parent_list=[child_list[i] for i in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#display loss\n",
    "plt.plot(np.arange(0,N_iter,1),np.array(minrloss))\n",
    "plt.plot(np.arange(0,N_iter,1),np.array(avgrloss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load the data output from get_neighbors\n",
    "graph_data=pd.read_csv('graph_commune.csv')\n",
    "graph_data['municipality']\n",
    "graph_data.columns=['index','neighbors indexes','municipality','neighbors']\n",
    "fusion2=fusion\n",
    "graph_data2=graph_data\n",
    "\n",
    "#replace with the name of the merged communes\n",
    "for elem in fusion:\n",
    "    graph_data2['municipality'][graph_data['municipality'].isin(elem[1:])]=elem[0]\n",
    "#check the differences\n",
    "common=pd.Series(list(set(data.index).intersection(set(graph_data2['municipality']))))\n",
    "diff1=pd.Series(list(set(data.index)-set(common)))\n",
    "diff2=pd.Series(list(set(graph_data2['municipality'])-set(common)))\n",
    "#set the remaining territories as lakes\n",
    "graph_data2['municipality'][graph_data['municipality'].isin(diff2)]='lac'\n",
    "fusion2.append(list(diff2))\n",
    "fusion2[-1].insert(0,'lac')\n",
    "\n",
    "#extracting the list of adjacent communes (string in the data)\n",
    "adjacency_list=[]\n",
    "for com in graph_data2['neighbors']:\n",
    "    j=re.findall('\"(.*?)\"[ \\n\\]]',com)\n",
    "    k=re.findall('\\'(.*?)\\'[ \\n\\]]',com)\n",
    "    k=[ (x.split('\\'', 1)[1] if \"\\'\" in x else x)for x in k ]\n",
    "    adjacency_list.append(k + j)\n",
    "\n",
    "#replace the name in the adjacent commune by the merged names\n",
    "for elem in fusion2:\n",
    "    for i,nei in enumerate(adjacency_list):\n",
    "        nei2=pd.Series(nei)\n",
    "        nei2[nei2.isin(elem[1:])]=elem[0]\n",
    "        adjacency_list[i]=list(nei2)\n",
    "\n",
    "#remove duplicates in adjacent communes\n",
    "for i,nei in enumerate(adjacency_list):\n",
    "    adjacency_list[i]=list(set(nei))\n",
    "\n",
    "#merge adjacent communes\n",
    "commune_list=list(set(graph_data2['municipality']))\n",
    "commune_list=list(pd.Series(commune_list).sort_values())\n",
    "adjacency_list_true=([[]]*len(commune_list))\n",
    "for i,elem in enumerate(commune_list):\n",
    "    for j,comm in enumerate(graph_data2['municipality']):\n",
    "        if elem==comm:\n",
    "            adjacency_list_true[i]=list(set(adjacency_list_true[i]).union(set(adjacency_list[j])))\n",
    "\n",
    "#set index instead of names\n",
    "adjacency_list_index=[]\n",
    "for i,elem in enumerate(commune_list):\n",
    "    h_list=[]\n",
    "    for adj_elem in adjacency_list_true[i]:\n",
    "        h_list.append(commune_list.index(adj_elem))\n",
    "    adjacency_list_index.append(h_list)\n",
    "\n",
    "#define graph\n",
    "N_comm=int(len(commune_list))\n",
    "adjacency_matrix=np.zeros((N_comm,N_comm))\n",
    "for i,elem in enumerate(commune_list):\n",
    "    for adj_elem in adjacency_list_index[i]:\n",
    "        b = np.zeros(N_comm)\n",
    "        b[ adj_elem ] = 1\n",
    "        adjacency_matrix[i,:]=adjacency_matrix[i,:]+b\n",
    "\n",
    "plt.spy(adjacency_matrix)\n",
    "#np.save(adjacency_matrix,'graph_adjacency.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('graph_adjacency.npy',adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_adjacency=np.load('graph_adjacency.npy')\n",
    "graph_new=graph_adjacency[:-1,:-1]\n",
    "del graph_adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=============== model parameters =============================\n",
    "K=26 #number of cantons\n",
    "N_repr=2 #number of representant per canton\n",
    "#==============================================================\n",
    "\n",
    "#=============== optimization parameters =============\n",
    "N_parents=15\n",
    "N_iter=100\n",
    "child_per_couple=2\n",
    "mute_probability=0.01\n",
    "lambda_graph=2\n",
    "#=====================================================\n",
    "\n",
    "#compute the global political opinion\n",
    "ground_truth = (pop_tab * np.transpose(data_tab)).sum(1)/pop_tab.sum()\n",
    "#initailize parent list\n",
    "parent_list = []\n",
    "for i in range(N_parents):\n",
    "    parent_list.append(np.random.randint(K,size=pop_tab.shape[0]))\n",
    "\n",
    "minloss=[]\n",
    "avgloss=[]\n",
    "\n",
    "minrloss=[]\n",
    "avgrloss=[]\n",
    "#perform optimization\n",
    "for iter in range(N_iter):\n",
    "    child_list = get_new_generation(parent_list,N_parents,child_per_couple,mute_probability,K)\n",
    "    \n",
    "    loss,rloss = compute_graph_loss(child_list,np.transpose(data_tab),pop_tab,N_repr,graph_new,K,lambda_graph)\n",
    "    loss=np.array(loss)\n",
    "    rloss=np.array(rloss)\n",
    "    minloss.append(loss.min())\n",
    "    avgloss.append(loss.mean())\n",
    "    minrloss.append(rloss.min())\n",
    "    avgrloss.append(rloss.mean())\n",
    "    \n",
    "    idx = loss.argsort()[:N_parents]\n",
    "    parent_list=[child_list[i] for i in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#display loss\n",
    "plt.plot(np.arange(0,N_iter,1),np.array(minrloss))\n",
    "plt.plot(np.arange(0,N_iter,1),np.array(avgrloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "series = pd.Series(child_list[0], index=data2.index.values)\n",
    "m_swiss = map_cantons(series, json_data_gemeinden, json_data_kantone)\n",
    "m_swiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
