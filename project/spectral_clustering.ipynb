{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import IPython.display as ipd\n",
    "plt.rcParams['figure.figsize'] = (17, 5)\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import codecs\n",
    "from scipy import sparse, stats, spatial\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import scipy.sparse.linalg\n",
    "import folium\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_party_data(path):\n",
    "    data=pd.read_excel(path)\n",
    "    data.drop([data.columns[0],data.columns[2],data.columns[3],data.columns[4]],1,inplace=True)\n",
    "    data.drop([0,1],0,inplace=True)\n",
    "    data.columns=['commune','party','percentage']\n",
    "    data=data.ffill()\n",
    "    data=data.groupby(['commune','party']).sum().unstack('party')\n",
    "    data2=data.reset_index()['percentage']\n",
    "    data2['commune']=data.reset_index()['commune']\n",
    "    return data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "data=load_party_data('data/partis_12prem_vote_2015.xlsx')\n",
    "data2=load_party_data('data/partis_12der_vote_2015.xlsx')\n",
    "#take only commune\n",
    "data=data[data['commune'].str.startswith('......')]\n",
    "data2=data2[data2['commune'].str.startswith('......')]\n",
    "data['commune']=data['commune'].str[7:]\n",
    "data2['commune']=data2['commune'].str[7:]\n",
    "#merge datasets\n",
    "data=pd.merge(data,data2,on='commune')\n",
    "#replace non-available parties with 0\n",
    "data.loc[:, data.columns != 'commune']=data.loc[:, data.columns != 'commune'].replace('...','0')\n",
    "#remove data from comming from correspondancies\n",
    "data=data[(data['commune'].str[:2]==(data['commune'].str.upper()).str[:2]) & (data['commune'].str[2]=='-') ==False]\n",
    "data.loc[:, data.columns != 'commune']=data.loc[:, data.columns != 'commune']\n",
    "data=data.set_index('commune')\n",
    "data.index=data.index.str.replace(re.escape(' (Urne commune)'),'')\n",
    "data=data.astype(float)\n",
    "data=data.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_tot=data.as_matrix()\n",
    "data_tot\n",
    "data.index.to_series()[data_tot.sum(1)==0]\n",
    "\n",
    "commune_with_no_vote=(data_tot.sum(1)==0)\n",
    "\n",
    "data_tot[commune_with_no_vote==False]=np.divide(data_tot[commune_with_no_vote==False],data_tot[commune_with_no_vote==False].sum(1)[:,None])\n",
    "\n",
    "data_tab=data_tot[commune_with_no_vote==False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "general=pd.read_excel('data/general_2015.xlsx')\n",
    "general=general[['Unnamed: 1','Unnamed: 9']]\n",
    "general.drop([0,1],0,inplace=True)\n",
    "general.columns=['commune','voters']\n",
    "#general=general[general['commune'].str.startswith('......')]\n",
    "general=general[general['commune'].str.startswith('......',na=False)]\n",
    "general['commune']=general['commune'].str[7:]\n",
    "general=general[(general['commune'].str[:2]==(general['commune'].str.upper()).str[:2]) & (general['commune'].str[2]=='-') ==False]\n",
    "general['voters']=general['voters'].replace('...','0')\n",
    "general['voters']=general['voters'].astype(int)\n",
    "general=general.set_index('commune')\n",
    "general=general.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pop_tot=np.squeeze(general.as_matrix())\n",
    "pop_tab=pop_tot[commune_with_no_vote==False]\n",
    "#plt.hist(pop_tab,bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We defined here a list of merged communes between 2013 and 2015, with the resulting commune in the first position\n",
    "\n",
    "\n",
    "fusion=[['Valbirse','Malleray','Bévilard','Pontenet'],\n",
    "        ['Terre di Pedemonte','Cavigliano','Tegna','Verscio'],\n",
    "        ['Val-de-Charmey','Charmey','Cerniat (FR)'],\n",
    "        ['Sauge','Frinvillier','Plagne','Vauffelin'],\n",
    "        ['Buchegg','Aetigkofen','Aetingen','Bibern (SO)','Brügglen','Gossliwil','Hessigkofen','Küttigkofen','Kyburg-Buchegg','Mühledorf (SO)','Tscheppach'],\n",
    "        ['Domleschg','Almens','Paspels','Pratval','Rodels','Tomils'],\n",
    "        ['Petit-Val','Châtelat','Monible','Sornetan','Souboz'],\n",
    "        ['Ilanz/Glion','Castrisch','Ilanz','Ladir','Luven','Pitasch','Riein','Ruschein','Schnaus','Sevgein','Duvin','Pigniu','Rueun','Siat'],\n",
    "        ['Péry-La Heutte','Péry','La Heutte'],\n",
    "        ['Calanca','Arvigo','Braggio','Cauco','Selma'],\n",
    "        ['Bettmeralp','Betten','Martisberg'],\n",
    "        ['Arzier-Le Muids','Arzier'],\n",
    "        ['Schinznach','Schinznach-Dorf','Oberflachs'],\n",
    "        ['Albula/Alvra','Alvaschein','Mon','Stierva','Tiefencastel','Alvaneu','Brienz/Brinzauls','Surava'],\n",
    "        ['Bussigny','Bussigny-près-Lausanne'],\n",
    "        ['Stocken-Höfen','Niederstocken','Oberstocken','Höfen'],\n",
    "        ['Plateau de Diesse','Diesse','Lamboing','Prêles'],\n",
    "        ['Mendrisio','Besazio','Ligornetto','Meride'],\n",
    "        ['Lugano','Bogno','Cadro','Carona','Certara','Cimadera','Sonvico','Valcolla'],\n",
    "        ['Bauma','Sternenberg'],\n",
    "        ['Scuol','Guarda','Ardez','Tarasp','Ftan','Sent'],\n",
    "        ['Jegenstorf','Scheunen','Münchringen'],\n",
    "        ['Fraubrunnen','Büren zum Hof','Etzelkofen','Grafenried','Limpach','Mülchi','Schalunen','Zauggenried'],\n",
    "        ['Murten','Staatswald Galm'],\n",
    "        ['Grafschaft','Kommunanz Reckingen-Gluringen/Grafschaft'],\n",
    "        ['Cadenazzo','Comunanza Cadenazzo/Monteceneri'],\n",
    "        ['Wiesendangen','Bertschikon'],\n",
    "        ['Innertkirchen','Gadmen'],\n",
    "        ['Endingen','Unterendingen'],\n",
    "        ['Uttigen','Kienersrüti'],\n",
    "        ['Bremgarten (AG)','Bremgarten','Hermetschwil-Staffeln'],\n",
    "        ['Zernez','Lavin','Susch'],\n",
    "        ['Oberdiessbach','Bleiken bei Oberdiessbach'],\n",
    "        ['Vals','St. Martin']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since the topojson for visualisation dates back to 2013, some old municipipalities in the topojson now unified are\n",
    "#missing in the dataset. Since it's complicated to find a topojson up to date, we will duplicate the data from the \n",
    "#unified municipalities to the old ones.\n",
    "\n",
    "#list of the old munipalities fron the topjson\n",
    "with open('data/gemeinden.topo.json') as f:\n",
    "    muni=json.load(f)\n",
    "    \n",
    "s= pd.DataFrame(muni['objects']['gemeinden']['geometries'])\n",
    "properties=s['properties'].values\n",
    "municipalities_topo = pd.DataFrame(list(properties))['GMDNAME']\n",
    "#municipalities_topo\n",
    "\n",
    "#list of the new municipalities from dataset\n",
    "#municipalities_data=data['commune']\n",
    "municipalities_data = pd.Series(data.index.values)\n",
    "municipalities_data.head()\n",
    "\n",
    "#diff of both: municipalities in top no it dataset\n",
    "diff_ind=~municipalities_topo.isin(municipalities_data) \n",
    "municipalities_diff= municipalities_topo[diff_ind]\n",
    "\n",
    "#for all diff munip create new row in data:\n",
    "#diff_df=pd.DataFrame(columns = data.columns, index= municipalities_diff)\n",
    "for old_munip in municipalities_diff:\n",
    "    #find corresponding new munip\n",
    "    for i in fusion:\n",
    "        for j in i:\n",
    "            if old_munip == j:\n",
    "                new_munip=i[0]\n",
    "                #copy row from data with corresponding to new munip\n",
    "                new_row=data.ix[new_munip]\n",
    "                new_row = pd.DataFrame(new_row.rename(old_munip)).T\n",
    "                data=data.append(new_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = data.sum(axis=0)/data.sum(axis=0).max()\n",
    "w.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only main parties\n",
    "data.drop([col for col, val in data.sum().iteritems() if val == 0], axis=1, inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start of spectral clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#distances = spatial.distance.squareform(spatial.distance.pdist(features,'wminkowski', p=1., w=w.values))\n",
    "distances = spatial.distance.squareform(spatial.distance.pdist(features,'minkowski', p=1.))\n",
    "#distances = spatial.distance.squareform(spatial.distance.pdist(features,'canberra'))\n",
    "#distances = spatial.distance.squareform(spatial.distance.pdist(features,'chebyshev'))\n",
    "#distances = spatial.distance.squareform(spatial.distance.pdist(features,'sqeuclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.spy(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} distances equal exactly zero.'.format(np.sum(distances == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_width = distances.mean()\n",
    "weights = np.exp(np.divide(-np.square(distances),kernel_width**2))\n",
    "np.fill_diagonal(weights,0)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(weights, axes):\n",
    "    axes[0].spy(weights)\n",
    "    axes[1].hist(weights[weights > 0].reshape(-1), bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, axes = plt.subplots(2, 2, figsize=(17, 8))\n",
    "plot(weights, axes[:, 0])\n",
    "\n",
    "NEIGHBORS = 350\n",
    "\n",
    "for i in range(weights.shape[0]):\n",
    "    idx = weights[i,:].argsort()[:-NEIGHBORS]\n",
    "    weights[i,idx] = 0\n",
    "    weights[idx,i] = 0\n",
    "\n",
    "plot(weights, axes[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = np.sum(weights,axis=0)\n",
    "plt.hist(degrees, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian = np.diag(degrees**-0.5) @ (np.diag(degrees) - weights) @ np.diag(degrees**-0.5)\n",
    "plt.spy(laplacian);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "laplacian = sparse.csr_matrix(laplacian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_edges = np.sum(np.ceil(weights))/2\n",
    "n_edges.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eigenvalues, eigenvectors = sparse.linalg.eigsh(A=laplacian,k=10,which='SM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eigenvalues, '.-', markersize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = eigenvectors[:,1]\n",
    "y = eigenvectors[:,2]\n",
    "labels = np.sign(x)\n",
    "\n",
    "plt.scatter(x, y, c=labels, cmap='RdBu', alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, axes = plt.subplots(5, 5, figsize=(17, 8))\n",
    "for i in range(1,6):\n",
    "    for j in range(1,6):\n",
    "        x = eigenvectors[:,i]\n",
    "        y = eigenvectors[:,j]\n",
    "        labels = np.sign(x)\n",
    "        axes[i-1,j-1].scatter(x, y, c=labels, cmap='RdBu', alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_1 = (eigenvectors[:,2] >= 0).astype(int)\n",
    "class_2 = (eigenvectors[:,3] >= 0).astype(int)\n",
    "class_3 = (eigenvectors[:,4] >= 0).astype(int)\n",
    "class_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = class_1 * 2**2 + class_2 * 2 + class_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "series = pd.Series(labels, index=data.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choropleth display :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_data_gemeinden = json.load(codecs.open('data/gemeinden.topo.json', 'r', 'utf-8-sig'))\n",
    "json_data_kantone = json.load(codecs.open('data/kantone.topo.json', 'r', 'utf-8-sig'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmap = matplotlib.cm.get_cmap('Spectral')\n",
    "color_map = cmap(np.arange(0,1,1/26))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def color(class_label, color_map): \n",
    "    return  {\n",
    "    'fillOpacity': 0.5,\n",
    "    'weight': 0.5,\n",
    "    'fillColor': '#%02x%02x%02x' % tuple((256 * color_map[class_label,:3]).astype(int)),\n",
    "    'color': '#%02x%02x%02x' % tuple((256 * color_map[class_label,:3]).astype(int))\n",
    "     }   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def style_function(data):    \n",
    "    if data['properties']['GMDNAME'] in series.index:\n",
    "        class_label = series[series.index == data['properties']['GMDNAME']][0]\n",
    "        return color(class_label, color_map)\n",
    "    \n",
    "    else:\n",
    "        return  {\n",
    "        'fillOpacity': 0.5,\n",
    "        'weight': 0.5,\n",
    "        'fillColor': '#%02x%02x%02x' % tuple((256 * color_map[0,:3]).astype(int)),\n",
    "        'color': '#%02x%02x%02x' % tuple((256 * color_map[0,:3]).astype(int))\n",
    "         } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_cantons(series, json_data_gemeinden, json_data_kantone):\n",
    "    center_coord = [46.8011111,8.2266667]\n",
    "    cantons_map = folium.Map(location=center_coord,\n",
    "                tiles='cartodbpositron',           \n",
    "                zoom_start=7.5)\n",
    "\n",
    "    scale = list(np.linspace(0.,series.max(),6))\n",
    "\n",
    "    \"\"\"\n",
    "    cantons_map.choropleth(geo_data=json_data_gemeinden, topojson='objects.gemeinden', \n",
    "        data=series,\n",
    "        key_on='feature.properties.GMDNAME',\n",
    "        threshold_scale=scale,\n",
    "        fill_color='YlOrRd', fill_opacity=0.6, line_opacity=0.3,\n",
    "        highlight = True)\n",
    "     \n",
    "     \"\"\"\n",
    "    folium.TopoJson(json_data_gemeinden,'objects.gemeinden',name='gemeiden',\n",
    "                    style_function=style_function).add_to(cantons_map)\n",
    "\n",
    "    folium.TopoJson(json_data_kantone,'objects.kantone',name='cantons',style_function=lambda feature: {\n",
    "            'color': 'blue',\n",
    "            'fillOpacity':0.0,\n",
    "            'weight': 2}).add_to(cantons_map)\n",
    "    \n",
    "    return cantons_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_swiss = map_cantons(series, json_data_gemeinden, json_data_kantone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_swiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#m_swiss.save('switzerland_spectral_clustering.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load geojson data for coordinates\n",
    "geo_json_data = json.load(open('data/map.geojson'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore geojson data : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features -> number of municipality -> geometry -> coordinates -> coordinates of first point of arc -> x or y\n",
    "# ! : make sure to get rid of extra dimensions\n",
    "# example : display x coordinate of first point of arc of first municipality\n",
    "#geo_json_data['features'][0]['geometry']['coordinates']\n",
    "#geo_json_data['features'][653]['geometry']['coordinates'][1][0]\n",
    "#np.squeeze(np.array(geo_json_data['features'][0]['geometry']['coordinates']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rescale(features):\n",
    "    # given n_sample x n_features\n",
    "    min_vals = features.min(axis=0)\n",
    "    max_vals = features.max(axis=0)\n",
    "    \n",
    "    return (features - min_vals) / (max_vals - min_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2324\n",
    "coordinates = np.empty((0, 2))\n",
    "for i in range(N): \n",
    "    # calculate position as mean of point of arc\n",
    "    position = np.reshape(np.array(geo_json_data['features'][i]['geometry']['coordinates'][0]),(-1,2)).mean(axis=0)\n",
    "\n",
    "    # append to coordinate array\n",
    "    coordinates = np.append(coordinates, [position], axis=0)\n",
    "    \n",
    "coordinates = 0.1 * rescale(coordinates)\n",
    "coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "political_features = eigenvectors[:,1:26]\n",
    "#mean = political_features.mean(axis=0)\n",
    "#std = political_features.std(axis=0)\n",
    "#political_features = (political_features-mean)/std\n",
    "#political_features = rescale(political_features)\n",
    "political_features = np.sign(eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cluster_features = np.concatenate((political_features,coordinates),axis=1)\n",
    "cluster_features = political_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clustering_model = DBSCAN(eps=0.15, min_samples=30, metric='cityblock', p=2)\n",
    "n_cantons = 26\n",
    "clustering_model = KMeans(n_clusters=n_cantons, init='k-means++', \n",
    "                          n_init=20, max_iter=500, tol=0.0001)\n",
    "\n",
    "gaussian_mixture = GaussianMixture(n_components=6, covariance_type='full', \n",
    "                                   tol=0.001, reg_covar=1e-06, max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = clustering_model.fit_predict(cluster_features)\n",
    "#gaussian_mixture.fit(cluster_features)\n",
    "#classes = gaussian_mixture.predict(cluster_features)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting misrepresentation : \n",
    "- set of voters V, i in V \n",
    "- set of Candidates C, c in C\n",
    "- w winner of district\n",
    "- set of districts D : D_1 ... D_z\n",
    "\n",
    "MR(V,D,F) = max_c score_f(c,V) / score_f(w,V) --> sum MR(municipality versus canton)\n",
    "instead : \n",
    "    for each canton\n",
    "        sum dist(repr municipality, repr canton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(classes == 1)\n",
    "general.iloc[idx].values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def misrepresentation_score(Data,General,Classes):\n",
    "\n",
    "    MR = []\n",
    "    n_cantons = Classes.max()-1\n",
    "    swiss_voters = General.values.sum()\n",
    "    N_seats = 0\n",
    "\n",
    "    # for each canton\n",
    "    for canton in range(n_cantons):\n",
    "        # get municipalities\n",
    "        idx = np.where(Classes == canton)\n",
    "        n_municipalities = len(idx)\n",
    "        canton_data = Data.iloc[idx]\n",
    "        canton_general = General.iloc[idx]\n",
    "\n",
    "        # aggregate results for entire canton\n",
    "        results_canton = canton_data.mean(axis=0)\n",
    "        n_voters = canton_general.values.sum()\n",
    "        \n",
    "        # for 200 seats in total in parlement\n",
    "        n_seats = math.ceil(155 * n_voters/swiss_voters)\n",
    "        N_seats += n_seats\n",
    "        \n",
    "        #print(results_canton)\n",
    "        results_canton = round(n_seats * results_canton) / (n_seats)\n",
    "        #print(results_canton)\n",
    "        \n",
    "        # calculate average of euclidean error (misrepresentation)\n",
    "        MR.append(np.mean(np.sqrt(((canton_data-results_canton)**2).sum(axis=1))))\n",
    "    \n",
    "    #print(N_seats)\n",
    "    return np.mean(MR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misrepresentation_score(data,general,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study effect of number of clusters\n",
    "cluster_range = 31\n",
    "\n",
    "scores = []\n",
    "\n",
    "for n_cantons in range(3,cluster_range):\n",
    "    print('number of cantons : ',n_cantons)\n",
    "    clustering_model = KMeans(n_clusters=n_cantons, init='k-means++', \n",
    "                          n_init=100, max_iter=500, tol=0.0001)\n",
    "    classes = clustering_model.fit_predict(cluster_features)\n",
    "    scores.append(misrepresentation_score(data,general,classes))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#municipality_labels = (classes+1)%6\n",
    "municipality_labels = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "municipality_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "series = pd.Series(municipality_labels, index=data.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_swiss = map_cantons(series, json_data_gemeinden, json_data_kantone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_swiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
